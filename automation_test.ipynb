{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:10.654424Z",
     "start_time": "2024-11-07T18:30:10.637939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.models import list_models\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "def log_message(message, level=\"info\"):\n",
    "    \"\"\"\n",
    "    Log a message, with support for info, warning, and error levels.\n",
    "    If the level is \"error\", this function raises a ValueError with the message.\n",
    "\n",
    "    Parameters:\n",
    "        message (str): The message to log.\n",
    "        level (str): The level of the message (\"info\", \"warning\", or \"error\").\n",
    "    \"\"\"\n",
    "    if level == \"info\":\n",
    "        print(f\"[INFO] {message}\")\n",
    "    elif level == \"warning\":\n",
    "        print(f\"[WARNING] {message}\")\n",
    "    elif level == \"error\":\n",
    "        print(f\"[ERROR] {message}\")\n",
    "        raise ValueError(message)  # Raise an error if level is \"error\"\n",
    "\n",
    "def sanitize_string(s):\n",
    "    \"\"\"\n",
    "    Convert a string to lowercase, strip special characters, and replace spaces with underscores.\n",
    "\n",
    "    Parameters:\n",
    "        s (str): The input string to sanitize.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized string.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    s = s.replace(' ', '_')\n",
    "    s = re.sub(r'[^a-z0-9_]', '', s)\n",
    "    return s\n",
    "\n",
    "def ensure_directory_exists(dir_path):\n",
    "    \"\"\"\n",
    "    Ensure the specified directory exists; create it if it does not, including required subdirectories.\n",
    "    Set permissions to 777 for the main directory and its contents recursively.\n",
    "\n",
    "    Parameters:\n",
    "        dir_path (str): The path of the directory to ensure exists.\n",
    "\n",
    "    Returns:\n",
    "        str: The absolute path of the directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # List of required subdirectories\n",
    "    subdirs = ['dataset', 'src', 'checkpoints', 'output']\n",
    "    dirs_to_clear = ['checkpoints', 'output']    \n",
    "    \n",
    "    # Create each subdirectory if it doesnâ€™t exist\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(dir_path, subdir)\n",
    "        os.makedirs(subdir_path, exist_ok=True)\n",
    "    \n",
    "    # Set permissions recursively for main directory and all subdirectories/files\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        os.chmod(root, 0o777)\n",
    "        for d in dirs:\n",
    "            os.chmod(os.path.join(root, d), 0o777)\n",
    "        for f in files:\n",
    "            os.chmod(os.path.join(root, f), 0o777)\n",
    "    \n",
    "    # Clear all contents in the specified directories\n",
    "    for clear_dir in dirs_to_clear:\n",
    "        clear_path = os.path.join(dir_path, clear_dir)\n",
    "        for filename in os.listdir(clear_path):\n",
    "            file_path = os.path.join(clear_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)  # Remove file or link\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # Remove directory and all contents\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "    return os.path.abspath(dir_path)\n",
    "\n",
    "def check_file_exists(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file exists at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path of the file to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file exists, False otherwise.\n",
    "    \"\"\"\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "def is_archive_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file is a valid archive (zip or tar).\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path of the file to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file is a valid archive, False otherwise.\n",
    "    \"\"\"\n",
    "    return zipfile.is_zipfile(file_path) or tarfile.is_tarfile(file_path)"
   ],
   "id": "d749f7e3abf77d99",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:10.672059Z",
     "start_time": "2024-11-07T18:30:10.660880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "\n",
    "\n",
    "def setup_project(prj_name, brd_name, model_type, project_folder=None, model_py_file=None, model_pth_file=None, torch_vision_model=None, dataset_type=None, custom_dataset=None, torch_vision_dataset=None):\n",
    "    \"\"\"\n",
    "    Set up a project with a specified structure, including creating necessary directories, \n",
    "    validating model type, and checking for necessary files.\n",
    "\n",
    "    Parameters:\n",
    "        prj_name (str): The name of the project.\n",
    "        model_type (str): The type of model ('untrained', 'custom_pretrained', or 'torch_vision_pretrained').\n",
    "        project_folder (str, optional): The main folder for the project. A new folder is generated if not provided.\n",
    "        model_py_file (str, optional): The filename of the Python script defining the model architecture, required for 'untrained' and 'custom_pretrained' models.\n",
    "        model_pth_file (str, optional): The filename of the .pth file with pre-trained weights, required for 'custom_pretrained' models.\n",
    "        torch_vision_model (str, optional): The name of the TorchVision model to load if 'torch_vision_pretrained' is selected.\n",
    "        dataset_type (str, optional): Type of dataset for 'untrained' models ('torch_vision_dataset' or 'custom_dataset').\n",
    "        custom_dataset (str, optional): Path to the custom dataset file for 'untrained' models with 'custom_dataset' dataset type.\n",
    "        torch_vision_dataset (str, optional): Name of the TorchVision dataset class for 'untrained' models with 'torch_vision_dataset' dataset type.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with project setup information.\n",
    "    \"\"\"\n",
    "    log_message(\"Setting up project\")\n",
    "    working_folder = \"/home/fastqnn/finn/notebooks/Fast-QNN/outputs/txaviour/\"\n",
    "    prj_info = {}\n",
    "    \n",
    "    # Ensure Project Name is provided\n",
    "    if not prj_name:\n",
    "        log_message(\"Project Name is required\", level=\"error\")\n",
    "\n",
    "    # Sanitize project name and set project info\n",
    "    prj_name_stripped = sanitize_string(prj_name)\n",
    "    display_name = prj_name\n",
    "    prj_info[\"Display_Name\"] = display_name\n",
    "    prj_info[\"Stripped_Name\"] = prj_name_stripped\n",
    "\n",
    "    if not project_folder:\n",
    "        # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # for production mode\n",
    "        timestamp = \"0\"\n",
    "        project_folder = f\"{working_folder}{prj_name_stripped}_{timestamp}\"\n",
    "    \n",
    "    folder_path = ensure_directory_exists(project_folder)\n",
    "    prj_info[\"Folder\"] = folder_path\n",
    "    \n",
    "    available_boards = pynq_part_map.keys()\n",
    "    if brd_name in available_boards:\n",
    "        prj_info[\"Board_name\"] = brd_name\n",
    "    else:\n",
    "        log_message(f\"'{brd_name}' is not a valid board name. Available board names are: {available_boards}\", level=\"error\")\n",
    "\n",
    "    # Validate Model Type\n",
    "    valid_model_types = [\"untrained\", \"custom_pretrained\", \"torch_vision_pretrained\"]\n",
    "    if model_type not in valid_model_types:\n",
    "        log_message(f\"Model Type must be one of {valid_model_types}\", level=\"error\")\n",
    "    prj_info['Model_Type'] = model_type\n",
    "    \n",
    "    # Handle Model Type specific requirements\n",
    "    if model_type in [\"untrained\", \"custom_pretrained\"]:\n",
    "        if not model_py_file or not check_file_exists(os.path.join(project_folder, 'src', model_py_file)):\n",
    "            log_message(f\"Model Py File '{model_py_file}' does not exist in '{project_folder}'\", level=\"error\")\n",
    "        prj_info[\"Model_Py_File\"] = model_py_file\n",
    "\n",
    "    if model_type == \"custom_pretrained\":\n",
    "        if not model_pth_file or not check_file_exists(os.path.join(project_folder, 'src', model_pth_file)):\n",
    "            log_message(f\"Model Pth File '{model_pth_file}' does not exist in '{project_folder}'\", level=\"error\")\n",
    "        prj_info[\"Model_Pth_File\"] = model_pth_file\n",
    "\n",
    "    if model_type == \"torch_vision_pretrained\":\n",
    "        available_models = list_models(module=models)\n",
    "        if not torch_vision_model or torch_vision_model not in available_models:\n",
    "            log_message(f\"Torch Vision Model must be one of: {available_models}\", level=\"error\")\n",
    "        prj_info[\"Torch_Vision_Model\"] = torch_vision_model\n",
    "\n",
    "    # Handle Dataset requirements for Untrained models\n",
    "    if model_type == \"untrained\":\n",
    "        if dataset_type not in [\"torch_vision_dataset\", \"custom_dataset\"]:\n",
    "            log_message(\"Dataset Type must be either 'Torch Vision' or 'Custom Dataset' for Untrained models\", level=\"error\")\n",
    "        prj_info[\"Dataset_Type\"] = dataset_type\n",
    "\n",
    "        if dataset_type == \"custom_dataset\":\n",
    "            custom_dataset_path = os.path.join(project_folder, 'dataset', custom_dataset)\n",
    "            if not custom_dataset or not check_file_exists(custom_dataset_path) or not is_archive_file(custom_dataset_path):\n",
    "                log_message(f\"Custom Dataset '{custom_dataset}' must exist in '{project_folder}' and be an archive file (zip or tar)\", level=\"error\")\n",
    "            prj_info[\"Custom_Dataset\"] = custom_dataset\n",
    "\n",
    "        elif dataset_type == \"torch_vision_dataset\":\n",
    "            available_datasets = [cls_name.lower() for cls_name in dir(datasets) if not cls_name.startswith('_')]\n",
    "            if not torch_vision_dataset or torch_vision_dataset.lower() not in available_datasets:\n",
    "                log_message(f\"Torch Vision Dataset must be one of: {available_datasets}\", level=\"error\")\n",
    "            prj_info[\"Torch_Vision_Dataset\"] = torch_vision_dataset\n",
    "            \n",
    "    log_message(f\"Project setup complete. {prj_name} has been initialized.\")\n",
    "    return prj_info"
   ],
   "id": "4df70eb120061ecb",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:10.706316Z",
     "start_time": "2024-11-07T18:30:10.698582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_torch_vision_model(model_name, src_folder, initial_channels = 3, max_size = 4096):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model from TorchVision and ensures all downloads are in the src folder of the Project.\n",
    "\n",
    "    Parameters:\n",
    "        initial_channels: \n",
    "        max_size: \n",
    "        model_name (str): The name of the pre-trained model to load (e.g., 'alexnet', 'resnet50').\n",
    "        src_folder (str): The folder where model downloads will be stored. Default is 'src'.\n",
    "                \n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded pre-trained model.\n",
    "    \"\"\"\n",
    "    log_message(f\"Loading Torch Vision Model: {model_name}\")\n",
    "    # Ensure the src folder exists\n",
    "    os.makedirs(src_folder, exist_ok=True)\n",
    "    # Set TORCH_HOME to the src folder to store the model downloads there\n",
    "    os.environ['TORCH_HOME'] = src_folder\n",
    "    # Load the model from torch.hub with the specified model name\n",
    "    torch_model = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
    "    # List of common input shapes to test first (both square and non-square)\n",
    "    common_shapes = [\n",
    "        (1, initial_channels, 32, 32),  # Typical for many models\n",
    "        (1, initial_channels, 28, 28),  # Typical for many models\n",
    "        (1, initial_channels, 224, 224),  # Typical for many models\n",
    "        (1, initial_channels, 299, 299),  # For models like Inception\n",
    "        (1, initial_channels, 128, 128),  # Smaller size\n",
    "        (1, initial_channels, 256, 256),  # Larger square size\n",
    "        (1, initial_channels, 320, 240),  # Common non-square size\n",
    "        (1, initial_channels, 240, 320),  # Non-square (swapped dimensions)\n",
    "        (1, initial_channels, 256, 128),  # Non-square\n",
    "        (1, initial_channels, 128, 256),  # Non-square (swapped)\n",
    "    ]\n",
    "\n",
    "    # Try common shapes first\n",
    "    for shape in common_shapes:\n",
    "        try:\n",
    "            dummy_input = torch.rand(*shape)\n",
    "            torch_model(dummy_input)\n",
    "            log_message(f\"Compatible common input shape found: {shape}\")\n",
    "            return torch_model, shape\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "    # If no common shape worked, test all possible square and non-square shapes up to max_size\n",
    "    for width in range(1, max_size + 1, 1):  # Step by 16 for efficiency\n",
    "        for height in range(1, max_size + 1, 1):\n",
    "            try:\n",
    "                dummy_input = torch.rand(1, initial_channels, width, height)\n",
    "                torch_model(dummy_input)\n",
    "                torch_model_input_shape = (1, initial_channels, width, height)\n",
    "                log_message(f\"Compatible input shape found: {torch_model_input_shape}\")\n",
    "                return torch_model, torch_model_input_shape\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "\n",
    "    log_message(\"Could not determine a compatible input shape within the specified range.\", level=\"error\")"
   ],
   "id": "e912d407f448ecb4",
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "id": "3b4a8b34b65b86a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:11.549528Z",
     "start_time": "2024-11-07T18:30:10.730160Z"
    }
   },
   "source": [
    "prj_name_input = \"AlexNet 1W1A Test\"\n",
    "board_name_input = \"Pynq-Z2\"\n",
    "prj_folder_input = sanitize_string(prj_name_input)\n",
    "model_type_input = \"torch_vision_pretrained\"\n",
    "torch_vision_model_input = \"alexnet\"\n",
    "Project_Info = setup_project(prj_name=prj_name_input, brd_name=board_name_input, model_type=model_type_input, torch_vision_model=torch_vision_model_input)\n",
    "\n",
    "input_model= None\n",
    "torch_vision_shape = None\n",
    "\n",
    "if Project_Info['Model_Type'] == \"untrained\":\n",
    "    log_message(\"Training for untrained models are not supported at the moment!\", level=\"error\")\n",
    "elif Project_Info['Model_Type'] == \"custom_pretrained\":\n",
    "    log_message(\"Custom Pretrained models are not supported at the moment!\", level=\"error\")\n",
    "elif Project_Info['Model_Type'] == \"torch_vision_pretrained\":\n",
    "    torch_vision_folder = os.path.join(Project_Info['Folder'],\"src\")\n",
    "    input_model, torch_vision_shape = load_torch_vision_model(Project_Info['Torch_Vision_Model'], torch_vision_folder)\n",
    "else:\n",
    "    log_message(\"Unsupported Model Type\", level=\"error\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up project\n",
      "[INFO] Project setup complete. AlexNet 1W1A Test has been initialized.\n",
      "[INFO] Loading Torch Vision Model: alexnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fastqnn/finn/notebooks/Fast-QNN/outputs/txaviour/alexnet_1w1a_test_0/src/hub/pytorch_vision_v0.10.0\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compatible common input shape found: (1, 3, 224, 224)\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:11.587764Z",
     "start_time": "2024-11-07T18:30:11.583980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_onnx_checkpoint(project_info, suffix):\n",
    "    \"\"\"\n",
    "    Generates the export path for ONNX files based on a specified suffix.\n",
    "\n",
    "    Parameters:\n",
    "        project_info (dict): Dictionary containing project information (e.g., 'Folder' and 'Stripped_Name').\n",
    "        suffix (str): The suffix to append to the exported ONNX filename (e.g., \"model1\" for \"model1_export.onnx\").\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the export file.\n",
    "    \"\"\"\n",
    "    log_message(f\"Saving Checkpoint: {suffix}\")\n",
    "    suffix = sanitize_string(suffix)\n",
    "    filename = f\"{project_info['Stripped_Name']}_{suffix}.onnx\"\n",
    "    return os.path.join(project_info['Folder'], \"checkpoints\", filename)\n"
   ],
   "id": "1f4ae7b982c2a64c",
   "outputs": [],
   "execution_count": 58
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:16.507929Z",
     "start_time": "2024-11-07T18:30:11.610440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "export_onnx_path = set_onnx_checkpoint(Project_Info,\"Brevitas Export\")\n",
    "export_qonnx(input_model, torch.randn(torch_vision_shape), export_onnx_path)\n",
    "qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Brevitas Export\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:21.728059Z",
     "start_time": "2024-11-07T18:30:16.527455Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "model = ModelWrapper(export_onnx_path)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"QONNX to FINN\"))"
   ],
   "id": "de436732503bc809",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/home_dir/.local/lib/python3.10/site-packages/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 14. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: QONNX to FINN\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:21.756103Z",
     "start_time": "2024-11-07T18:30:21.751069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "\n",
    "def tidy_up_transforms(input_tidy_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a series of transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_tidy_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply transformations\n",
    "    input_tidy_model = input_tidy_model.transform(InferShapes())\n",
    "    input_tidy_model = input_tidy_model.transform(FoldConstants())\n",
    "    input_tidy_model = input_tidy_model.transform(GiveUniqueNodeNames())\n",
    "    input_tidy_model = input_tidy_model.transform(GiveReadableTensorNames())\n",
    "    input_tidy_model = input_tidy_model.transform(InferDataTypes())\n",
    "    input_tidy_model = input_tidy_model.transform(RemoveStaticGraphInputs())\n",
    "    input_tidy_model = input_tidy_model.transform(InferDataLayouts())\n",
    "    input_tidy_model = input_tidy_model.transform(RemoveUnusedTensors())\n",
    "\n",
    "    # Save the transformed model\n",
    "    input_tidy_model.save(save_name)\n",
    "\n",
    "    return input_tidy_model"
   ],
   "id": "a5d959d6407a1ec2",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:24.419302Z",
     "start_time": "2024-11-07T18:30:21.776722Z"
    }
   },
   "cell_type": "code",
   "source": "model = tidy_up_transforms(model, set_onnx_checkpoint(Project_Info,\"Tidy ONNX Post Finn\"))",
   "id": "21fb27ba948a8cbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Tidy ONNX Post Finn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/home_dir/.local/lib/python3.10/site-packages/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:25.167723Z",
     "start_time": "2024-11-07T18:30:24.442476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.util.pytorch import ToTensor\n",
    "\n",
    "# log_message(\"Skipping Pre-Processing. Will be expecting the user to handle it in application!\", level=\"warning\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = set_onnx_checkpoint(Project_Info,\"Pre Proc ONNX Finn\")\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])"
   ],
   "id": "57af62ce8ef3c010",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Pre Proc ONNX Finn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/home_dir/.local/lib/python3.10/site-packages/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:26.389796Z",
     "start_time": "2024-11-07T18:30:25.206181Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"Post Processing\"))\n",
    "model = tidy_up_transforms(model, set_onnx_checkpoint(Project_Info,\"Tidy Post PrePost Proc\"))"
   ],
   "id": "49bbd723443c4e65",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Post Processing\n",
      "[INFO] Saving Checkpoint: Tidy Post PrePost Proc\n"
     ]
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:30:26.399927Z",
     "start_time": "2024-11-07T18:30:26.394997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.absorb import AbsorbTransposeIntoMultiThreshold, AbsorbScalarMulAddIntoTopK\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "def streamline_transforms(input_streamline_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a series of streamlining transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_streamline_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply streamlining transformations\n",
    "    input_streamline_model = input_streamline_model.transform(MoveScalarLinearPastInvariants())\n",
    "    input_streamline_model = input_streamline_model.transform(Streamline())\n",
    "    input_streamline_model = input_streamline_model.transform(LowerConvsToMatMul())\n",
    "    input_streamline_model = input_streamline_model.transform(MakeMaxPoolNHWC())\n",
    "    input_streamline_model = input_streamline_model.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "    input_streamline_model = input_streamline_model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "    input_streamline_model = input_streamline_model.transform(Streamline())\n",
    "    input_streamline_model = input_streamline_model.transform(AbsorbScalarMulAddIntoTopK())\n",
    "\n",
    "    # Save the transformed model after tidying up\n",
    "    input_streamline_model = tidy_up_transforms(input_streamline_model, save_name)\n",
    "\n",
    "    return input_streamline_model"
   ],
   "id": "6bdb92934093ceb8",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:01.173378Z",
     "start_time": "2024-11-07T18:30:26.422157Z"
    }
   },
   "cell_type": "code",
   "source": "model = streamline_transforms(model, set_onnx_checkpoint(Project_Info,\"Streamlined ONNX\"))",
   "id": "d969950c0d96fc53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Streamlined ONNX\n"
     ]
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:01.199838Z",
     "start_time": "2024-11-07T18:31:01.193325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.streamline.absorb import AbsorbConsecutiveTransposes\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.fpgadataflow.convert_to_hw_layers import (InferBinaryMatrixVectorActivation,\n",
    "                                                                   InferQuantizedMatrixVectorActivation, \n",
    "                                                                   InferLabelSelectLayer, \n",
    "                                                                   InferThresholdingLayer, \n",
    "                                                                   InferStreamingMaxPool,\n",
    "                                                                   InferConvInpGen)\n",
    "\n",
    "\n",
    "def to_hw_transforms(input_hw_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a series of hardware-oriented transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_hw_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply hardware transformations\n",
    "    input_hw_model = input_hw_model.transform(InferBinaryMatrixVectorActivation())\n",
    "    input_hw_model = input_hw_model.transform(InferQuantizedMatrixVectorActivation())\n",
    "    input_hw_model = input_hw_model.transform(InferLabelSelectLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferThresholdingLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferConvInpGen())\n",
    "    input_hw_model = input_hw_model.transform(InferStreamingMaxPool())\n",
    "    input_hw_model = input_hw_model.transform(RemoveCNVtoFCFlatten())\n",
    "    input_hw_model = input_hw_model.transform(AbsorbConsecutiveTransposes())\n",
    "    \n",
    "    # Save the transformed model after tidying up\n",
    "    input_hw_model = tidy_up_transforms(input_hw_model, save_name)\n",
    "\n",
    "    # Save the transformed model\n",
    "    input_hw_model.save(save_name)\n",
    "\n",
    "    return input_hw_model\n"
   ],
   "id": "e34005da6e651b95",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.461293Z",
     "start_time": "2024-11-07T18:31:01.229539Z"
    }
   },
   "cell_type": "code",
   "source": "model = to_hw_transforms(model, set_onnx_checkpoint(Project_Info,\"To HW Layers\"))",
   "id": "3231949dbb03adb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: To HW Layers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:63: UserWarning: Im2Col_1 : Input is not int. Can't infer ConvInpGen.\n",
      "  warnings.warn(\"%s : Input is not int. Can't infer ConvInpGen.\" % n.name)\n",
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:63: UserWarning: Im2Col_2 : Input is not int. Can't infer ConvInpGen.\n",
      "  warnings.warn(\"%s : Input is not int. Can't infer ConvInpGen.\" % n.name)\n",
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:63: UserWarning: Im2Col_3 : Input is not int. Can't infer ConvInpGen.\n",
      "  warnings.warn(\"%s : Input is not int. Can't infer ConvInpGen.\" % n.name)\n",
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:63: UserWarning: Im2Col_4 : Input is not int. Can't infer ConvInpGen.\n",
      "  warnings.warn(\"%s : Input is not int. Can't infer ConvInpGen.\" % n.name)\n",
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/convert_to_hw_layers.py:394: UserWarning: Stride is not equal to kernel. Node cannot be converted to\n",
      "                        StreamingMaxPool layer.\n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.487342Z",
     "start_time": "2024-11-07T18:31:03.483112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "def dataflow_partitioning(input_data_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies dataflow partitioning transformation to the model and saves the resulting parent and dataflow models.\n",
    "\n",
    "    Parameters:\n",
    "        input_data_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The directory to save the transformed models.\n",
    "\n",
    "    Returns:\n",
    "        ModelWrapper: The transformed parent model.\n",
    "    \"\"\"\n",
    "    # Apply dataflow partitioning\n",
    "    parent_model = input_data_model.transform(CreateDataflowPartition())\n",
    "    parent_model.save(save_name)\n",
    "    \n",
    "    # Retrieve the dataflow partition model filename\n",
    "    sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "    sdp_node = getCustomOp(sdp_node)\n",
    "    dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "    # Load and return the dataflow model\n",
    "    dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "    \n",
    "    return dataflow_model"
   ],
   "id": "7b896786bf7eccae",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.793282Z",
     "start_time": "2024-11-07T18:31:03.517948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = dataflow_partitioning(model, set_onnx_checkpoint(Project_Info,\"Dataflow Partition Parent Model\"))\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"Dataflow Partition Streaming Model\"))"
   ],
   "id": "a18f4bf215064d2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Dataflow Partition Parent Model\n",
      "[INFO] Saving Checkpoint: Dataflow Partition Streaming Model\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.817721Z",
     "start_time": "2024-11-07T18:31:03.813687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "\n",
    "def specialize_layers_transform(input_specialize_model, board_name, save_name):\n",
    "    \"\"\"\n",
    "    Applies layer specialization transformation to a dataflow model for the specified FPGA part and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_specialize_model (ModelWrapper): The dataflow model to transform.\n",
    "        board_name (str): The FPGA board for which to specialize the layers.\n",
    "        save_name (str): The path to save the specialized model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed and specialized dataflow model.\n",
    "    \"\"\"\n",
    "    fpga_part = pynq_part_map[board_name]\n",
    "    # Apply specialization for FPGA layers\n",
    "    input_specialize_model = input_specialize_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "    # Save the specialized model\n",
    "    input_specialize_model.save(save_name)\n",
    "\n",
    "    return input_specialize_model"
   ],
   "id": "29068574207cfe2",
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.840923Z",
     "start_time": "2024-11-07T18:31:03.837051Z"
    }
   },
   "cell_type": "code",
   "source": "model = specialize_layers_transform(model, Project_Info['Board_name'], set_onnx_checkpoint(Project_Info,f\"Specialize Model Layers to {Project_Info['Board_name']}\"))",
   "id": "66573cba9e8b29aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Specialize Model Layers to Pynq-Z2\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.868739Z",
     "start_time": "2024-11-07T18:31:03.863269Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def folding_transform(input_folding_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies folding configuration to fully connected (MVAU_hls) and sliding window (ConvolutionInputGenerator_rtl)\n",
    "    layers in the model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_folding_model (ModelWrapper): The specialized model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed and folded dataflow model.\n",
    "    \"\"\"\n",
    "    folding_config = [\n",
    "    (16, 3, [128]),\n",
    "    (32, 32, [128]),\n",
    "    (16, 32, [128]),\n",
    "    (16, 32, [128]),\n",
    "    (4, 32, [81]),\n",
    "    (1, 32, [2]),\n",
    "    (1, 4, [2]),\n",
    "    (1, 8, [128]),\n",
    "    (5, 1, [3]),\n",
    "    ]\n",
    "    \n",
    "    # Apply folding configuration to fully connected layers\n",
    "    fc_layers = input_folding_model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "    for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding_config):\n",
    "        fcl_inst = getCustomOp(fcl)\n",
    "        fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "        fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "        fcl_inst.set_nodeattr(\"inFIFODepths\", ififodepth)\n",
    "    \n",
    "    # Apply SIMD values from the folding configuration to sliding window layers\n",
    "    swg_layers = input_folding_model.get_nodes_by_op_type(\"ConvolutionInputGenerator_rtl\")\n",
    "    for i in range(len(swg_layers)):\n",
    "        swg_inst = getCustomOp(swg_layers[i])\n",
    "        simd = folding_config[i][1]\n",
    "        swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "    # Apply unique node names to all nodes and save the transformed model\n",
    "    input_folding_model = input_folding_model.transform(GiveUniqueNodeNames())\n",
    "    input_folding_model.save(save_name)\n",
    "\n",
    "    return input_folding_model\n"
   ],
   "id": "cd5527c3889d3ed2",
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.892542Z",
     "start_time": "2024-11-07T18:31:03.888234Z"
    }
   },
   "cell_type": "code",
   "source": "model = folding_transform(model, set_onnx_checkpoint(Project_Info, \"Folded Model\"))",
   "id": "1269bd96fdeb9db3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Folded Model\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.919212Z",
     "start_time": "2024-11-07T18:31:03.915519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "\n",
    "def zynq_build_transform(input_zynq_model, save_name, brd_name):\n",
    "    \"\"\"\n",
    "    Applies the ZynqBuild transformation to a model for the specified PYNQ board and clock period.\n",
    "\n",
    "    Parameters:\n",
    "        input_zynq_model (ModelWrapper): Folded model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "        brd_name (str): Name of the PYNQ board to target.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model after applying ZynqBuild.\n",
    "    \"\"\"\n",
    "    target_clk_ns = 10\n",
    "    # Apply ZynqBuild transformation\n",
    "    input_zynq_model = input_zynq_model.transform(ZynqBuild(platform=brd_name, period_ns=target_clk_ns))\n",
    "    \n",
    "    # Save the transformed model\n",
    "    input_zynq_model.save(save_name)\n",
    "\n",
    "    return input_zynq_model\n"
   ],
   "id": "394bed78132471e6",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:03.943093Z",
     "start_time": "2024-11-07T18:31:03.939717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "\n",
    "def pynq_driver_transform(input_driver_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies the MakePYNQDriver transformation to the model to generate a PYNQ-compatible driver.\n",
    "\n",
    "    Parameters:\n",
    "        input_driver_model (ModelWrapper): ZynqBuild model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model with PYNQ driver compatibility.\n",
    "    \"\"\"\n",
    "    # Apply MakePYNQDriver transformation\n",
    "    input_driver_model = input_driver_model.transform(MakePYNQDriver(\"zynq-iodma\"))\n",
    "    \n",
    "    # Save the transformed model\n",
    "    input_driver_model.save(save_name)\n",
    "\n",
    "    return input_driver_model\n"
   ],
   "id": "d1f6d7caa00a8452",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T18:31:28.626643Z",
     "start_time": "2024-11-07T18:31:17.819284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = zynq_build_transform(model, set_onnx_checkpoint(Project_Info, \"Zynq Build\"), Project_Info['Board_name'])\n",
    "model = pynq_driver_transform(model, set_onnx_checkpoint(Project_Info, \"Pynq Driver\"))"
   ],
   "id": "669b7375d6509996",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Zynq Build\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 4 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mzynq_build_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mset_onnx_checkpoint\u001B[49m\u001B[43m(\u001B[49m\u001B[43mProject_Info\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mZynq Build\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mProject_Info\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBoard_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m pynq_driver_transform(model, set_onnx_checkpoint(Project_Info, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPynq Driver\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n",
      "Cell \u001B[0;32mIn[75], line 17\u001B[0m, in \u001B[0;36mzynq_build_transform\u001B[0;34m(input_zynq_model, save_name, brd_name)\u001B[0m\n\u001B[1;32m     15\u001B[0m target_clk_ns \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Apply ZynqBuild transformation\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m input_zynq_model \u001B[38;5;241m=\u001B[39m \u001B[43minput_zynq_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mZynqBuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplatform\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbrd_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mperiod_ns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget_clk_ns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Save the transformed model\u001B[39;00m\n\u001B[1;32m     20\u001B[0m input_zynq_model\u001B[38;5;241m.\u001B[39msave(save_name)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/core/modelwrapper.py:140\u001B[0m, in \u001B[0;36mModelWrapper.transform\u001B[0;34m(self, transformation, make_deepcopy, cleanup)\u001B[0m\n\u001B[1;32m    138\u001B[0m model_was_changed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m model_was_changed:\n\u001B[0;32m--> 140\u001B[0m     (transformed_model, model_was_changed) \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[1;32m    142\u001B[0m     transformed_model\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m/home/fastqnn/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py:345\u001B[0m, in \u001B[0;36mZynqBuild.apply\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    343\u001B[0m kernel_model\u001B[38;5;241m.\u001B[39msave(dataflow_model_filename)\n\u001B[1;32m    344\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m kernel_model\u001B[38;5;241m.\u001B[39mtransform(PrepareIP(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpga_part, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiod_ns))\n\u001B[0;32m--> 345\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m \u001B[43mkernel_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mHLSSynthIP\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m kernel_model\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m    347\u001B[0m     CreateStitchedIP(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpga_part, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiod_ns, sdp_node\u001B[38;5;241m.\u001B[39monnx_node\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    348\u001B[0m )\n\u001B[1;32m    349\u001B[0m kernel_model\u001B[38;5;241m.\u001B[39mset_metadata_prop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplatform\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzynq-iodma\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/core/modelwrapper.py:140\u001B[0m, in \u001B[0;36mModelWrapper.transform\u001B[0;34m(self, transformation, make_deepcopy, cleanup)\u001B[0m\n\u001B[1;32m    138\u001B[0m model_was_changed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m model_was_changed:\n\u001B[0;32m--> 140\u001B[0m     (transformed_model, model_was_changed) \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[1;32m    142\u001B[0m     transformed_model\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/transformation/base.py:112\u001B[0m, in \u001B[0;36mNodeLocalTransformation.apply\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m mp\u001B[38;5;241m.\u001B[39mPool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers) \u001B[38;5;28;01mas\u001B[39;00m p:\n\u001B[0;32m--> 112\u001B[0m         new_nodes_and_bool \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplyNodeLocal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mold_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# execute without mp.Pool in case of 1 worker to simplify debugging\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m     new_nodes_and_bool \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapplyNodeLocal(node) \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m old_nodes]\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    363\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 768\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    770\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 77
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
