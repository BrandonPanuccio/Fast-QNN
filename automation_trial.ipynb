{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:07:10.379608Z",
     "start_time": "2024-11-13T06:07:09.008101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import tarfile\n",
    "import zipfile\n",
    "\n",
    "from torchvision import datasets\n",
    "from torchvision.models import list_models\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "\n",
    "def log_message(message, level=\"info\"):\n",
    "    \"\"\"\n",
    "    Log a message, with support for info, warning, and error levels.\n",
    "    If the level is \"error\", this function raises a ValueError with the message.\n",
    "\n",
    "    Parameters:\n",
    "        message (str): The message to log.\n",
    "        level (str): The level of the message (\"info\", \"warning\", or \"error\").\n",
    "    \"\"\"\n",
    "    if level == \"info\":\n",
    "        print(f\"[INFO] {message}\")\n",
    "    elif level == \"warning\":\n",
    "        print(f\"[WARNING] {message}\")\n",
    "    elif level == \"error\":\n",
    "        print(f\"[ERROR] {message}\")\n",
    "        raise ValueError(message)  # Raise an error if level is \"error\"\n",
    "\n",
    "def sanitize_string(s):\n",
    "    \"\"\"\n",
    "    Convert a string to lowercase, strip special characters, and replace spaces with underscores.\n",
    "\n",
    "    Parameters:\n",
    "        s (str): The input string to sanitize.\n",
    "\n",
    "    Returns:\n",
    "        str: The sanitized string.\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    s = s.replace(' ', '_')\n",
    "    s = re.sub(r'[^a-z0-9_]', '', s)\n",
    "    return s\n",
    "\n",
    "def ensure_directory_exists(dir_path):\n",
    "    \"\"\"\n",
    "    Ensure the specified directory exists; create it if it does not, including required subdirectories.\n",
    "    Set permissions to 777 for the main directory and its contents recursively.\n",
    "\n",
    "    Parameters:\n",
    "        dir_path (str): The path of the directory to ensure exists.\n",
    "\n",
    "    Returns:\n",
    "        str: The absolute path of the directory.\n",
    "    \"\"\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    # List of required subdirectories\n",
    "    subdirs = ['dataset', 'src', 'checkpoints', 'output']\n",
    "    dirs_to_clear = ['checkpoints', 'output']    \n",
    "    \n",
    "    # Create each subdirectory if it doesnâ€™t exist\n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(dir_path, subdir)\n",
    "        os.makedirs(subdir_path, exist_ok=True)\n",
    "    \n",
    "    # Set permissions recursively for main directory and all subdirectories/files\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        os.chmod(root, 0o777)\n",
    "        for d in dirs:\n",
    "            os.chmod(os.path.join(root, d), 0o777)\n",
    "        for f in files:\n",
    "            os.chmod(os.path.join(root, f), 0o777)\n",
    "    \n",
    "    # Clear all contents in the specified directories\n",
    "    for clear_dir in dirs_to_clear:\n",
    "        clear_path = os.path.join(dir_path, clear_dir)\n",
    "        for filename in os.listdir(clear_path):\n",
    "            file_path = os.path.join(clear_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)  # Remove file or link\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # Remove directory and all contents\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "\n",
    "    return os.path.abspath(dir_path)\n",
    "\n",
    "def check_file_exists(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file exists at the specified path.\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path of the file to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file exists, False otherwise.\n",
    "    \"\"\"\n",
    "    return os.path.isfile(file_path)\n",
    "\n",
    "def is_archive_file(file_path):\n",
    "    \"\"\"\n",
    "    Check if a file is a valid archive (zip or tar).\n",
    "\n",
    "    Parameters:\n",
    "        file_path (str): The path of the file to check.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the file is a valid archive, False otherwise.\n",
    "    \"\"\"\n",
    "    return zipfile.is_zipfile(file_path) or tarfile.is_tarfile(file_path)"
   ],
   "id": "d749f7e3abf77d99",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:07:10.406296Z",
     "start_time": "2024-11-13T06:07:10.386861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.util.basic import pynq_part_map\n",
    "\n",
    "\n",
    "def setup_project(prj_name, brd_name, model_type, project_folder=None, model_py_file=None, model_pth_file=None, torch_vision_model=None, finn_pretrained_model=None, dataset_type=None, custom_dataset=None, torch_vision_dataset=None):\n",
    "    \"\"\"\n",
    "    Set up a project with a specified structure, including creating necessary directories, \n",
    "    validating model type, and checking for necessary files.\n",
    "\n",
    "    Parameters:\n",
    "        finn_pretrained_model: \n",
    "        prj_name (str): The name of the project.\n",
    "        model_type (str): The type of model ('untrained', 'custom_pretrained', or 'torch_vision_pretrained').\n",
    "        project_folder (str, optional): The main folder for the project. A new folder is generated if not provided.\n",
    "        model_py_file (str, optional): The filename of the Python script defining the model architecture, required for 'untrained' and 'custom_pretrained' models.\n",
    "        model_pth_file (str, optional): The filename of the .pth file with pre-trained weights, required for 'custom_pretrained' models.\n",
    "        torch_vision_model (str, optional): The name of the TorchVision model to load if 'torch_vision_pretrained' is selected.\n",
    "        dataset_type (str, optional): Type of dataset for 'untrained' models ('torch_vision_dataset' or 'custom_dataset').\n",
    "        custom_dataset (str, optional): Path to the custom dataset file for 'untrained' models with 'custom_dataset' dataset type.\n",
    "        torch_vision_dataset (str, optional): Name of the TorchVision dataset class for 'untrained' models with 'torch_vision_dataset' dataset type.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary with project setup information.\n",
    "    \"\"\"\n",
    "    log_message(\"Setting up project\")\n",
    "    working_folder = \"/home/fastqnn/finn/notebooks/Fast-QNN/outputs/txaviour/\"\n",
    "    prj_info = {}\n",
    "    \n",
    "    # Ensure Project Name is provided\n",
    "    if not prj_name:\n",
    "        log_message(\"Project Name is required\", level=\"error\")\n",
    "\n",
    "    # Sanitize project name and set project info\n",
    "    prj_name_stripped = sanitize_string(prj_name)\n",
    "    display_name = prj_name\n",
    "    prj_info[\"Display_Name\"] = display_name\n",
    "    prj_info[\"Stripped_Name\"] = prj_name_stripped\n",
    "\n",
    "    if not project_folder:\n",
    "        # timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # for production mode\n",
    "        timestamp = \"0\"\n",
    "        project_folder = f\"{working_folder}{prj_name_stripped}_{timestamp}\"\n",
    "    \n",
    "    folder_path = ensure_directory_exists(project_folder)\n",
    "    prj_info[\"Folder\"] = folder_path\n",
    "    \n",
    "    available_boards = pynq_part_map.keys()\n",
    "    if brd_name in available_boards:\n",
    "        prj_info[\"Board_name\"] = brd_name\n",
    "    else:\n",
    "        log_message(f\"'{brd_name}' is not a valid board name. Available board names are: {available_boards}\", level=\"error\")\n",
    "\n",
    "    # Validate Model Type\n",
    "    valid_model_types = [\"untrained\", \"custom_pretrained\", \"torch_vision_pretrained\", \"finn_pretrained\"]\n",
    "    if model_type not in valid_model_types:\n",
    "        log_message(f\"Model Type must be one of {valid_model_types}\", level=\"error\")\n",
    "    prj_info['Model_Type'] = model_type\n",
    "    \n",
    "    # Handle Model Type specific requirements\n",
    "    if model_type in [\"untrained\", \"custom_pretrained\"]:\n",
    "        if not model_py_file or not check_file_exists(os.path.join(project_folder, 'src', model_py_file)):\n",
    "            log_message(f\"Model Py File '{model_py_file}' does not exist in '{project_folder}'\", level=\"error\")\n",
    "        prj_info[\"Model_Py_File\"] = model_py_file\n",
    "\n",
    "    if model_type == \"custom_pretrained\":\n",
    "        if not model_pth_file or not check_file_exists(os.path.join(project_folder, 'src', model_pth_file)):\n",
    "            log_message(f\"Model Pth File '{model_pth_file}' does not exist in '{project_folder}'\", level=\"error\")\n",
    "        prj_info[\"Model_Pth_File\"] = model_pth_file\n",
    "\n",
    "    if model_type == \"torch_vision_pretrained\":\n",
    "        available_models = list_models(module=models)\n",
    "        if not torch_vision_model or torch_vision_model not in available_models:\n",
    "            log_message(f\"Torch Vision Model must be one of: {available_models}\", level=\"error\")\n",
    "        prj_info[\"Torch_Vision_Model\"] = torch_vision_model\n",
    "\n",
    "    if model_type == \"finn_pretrained\":\n",
    "        available_models = [\"cnv_1w1a\", \"cnv_1w2a\", \"cnv_2w2a\", \"lfc_1w1a\", \"lfc_1w2a\", \"sfc_1w1a\", \"sfc_1w2a\", \"sfc_2w2a\", \"tfc_1w1a\", \"tfc_1w2a\", \"tfc_2w2a\", \"quant_mobilenet_v1_4b\"]\n",
    "        if not finn_pretrained_model or finn_pretrained_model not in available_models:\n",
    "            log_message(f\"Finn Pretrained Model must be one of: {available_models}\", level=\"error\")\n",
    "        prj_info[\"Finn_Pretrained_Model\"] = finn_pretrained_model\n",
    "\n",
    "    # Handle Dataset requirements for Untrained models\n",
    "    if model_type == \"untrained\":\n",
    "        if dataset_type not in [\"torch_vision_dataset\", \"custom_dataset\"]:\n",
    "            log_message(\"Dataset Type must be either 'Torch Vision' or 'Custom Dataset' for Untrained models\", level=\"error\")\n",
    "        prj_info[\"Dataset_Type\"] = dataset_type\n",
    "\n",
    "        if dataset_type == \"custom_dataset\":\n",
    "            custom_dataset_path = os.path.join(project_folder, 'dataset', custom_dataset)\n",
    "            if not custom_dataset or not check_file_exists(custom_dataset_path) or not is_archive_file(custom_dataset_path):\n",
    "                log_message(f\"Custom Dataset '{custom_dataset}' must exist in '{project_folder}' and be an archive file (zip or tar)\", level=\"error\")\n",
    "            prj_info[\"Custom_Dataset\"] = custom_dataset\n",
    "\n",
    "        elif dataset_type == \"torch_vision_dataset\":\n",
    "            available_datasets = [cls_name.lower() for cls_name in dir(datasets) if not cls_name.startswith('_')]\n",
    "            if not torch_vision_dataset or torch_vision_dataset.lower() not in available_datasets:\n",
    "                log_message(f\"Torch Vision Dataset must be one of: {available_datasets}\", level=\"error\")\n",
    "            prj_info[\"Torch_Vision_Dataset\"] = torch_vision_dataset\n",
    "            \n",
    "    log_message(f\"Project setup complete. {prj_name} has been initialized.\")\n",
    "    return prj_info"
   ],
   "id": "4df70eb120061ecb",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:07:11.356683Z",
     "start_time": "2024-11-13T06:07:10.516748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.util.test import get_test_model_trained\n",
    "\n",
    "\n",
    "def load_pretrained_model(model_name, model_type, src_folder, initial_channels = 3, max_size = 4096):\n",
    "    \"\"\"\n",
    "    Loads a pre-trained model from TorchVision and ensures all downloads are in the src folder of the Project.\n",
    "\n",
    "    Parameters:\n",
    "        model_type: \n",
    "        initial_channels: \n",
    "        max_size: \n",
    "        model_name (str): The name of the pre-trained model to load (e.g., 'alexnet', 'resnet50').\n",
    "        src_folder (str): The folder where model downloads will be stored. Default is 'src'.\n",
    "                \n",
    "    Returns:\n",
    "        torch.nn.Module: The loaded pre-trained model.\n",
    "    \"\"\"\n",
    "    log_message(f\"Loading {model_type} Model: {model_name}\")\n",
    "    # Ensure the src folder exists\n",
    "    os.makedirs(src_folder, exist_ok=True)\n",
    "    # Set TORCH_HOME to the src folder to store the model downloads there\n",
    "    os.environ['TORCH_HOME'] = src_folder\n",
    "    pretrained_model = None\n",
    "    if model_type == \"torch_vision_pretrained\":\n",
    "        # Load the model from torch.hub with the specified model name\n",
    "        pretrained_model = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
    "    elif model_type == \"finn_pretrained\":\n",
    "        if model_name == \"cnv_1w1a\":\n",
    "            pretrained_model = get_test_model_trained(\"CNV\", 1, 1)\n",
    "        elif model_name == \"cnv_1w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"CNV\", 1, 2)\n",
    "        elif model_name == \"cnv_2w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"CNV\", 2, 2)\n",
    "        elif model_name == \"lfc_1w1a\":\n",
    "            pretrained_model = get_test_model_trained(\"LFC\", 1, 1)\n",
    "        elif model_name == \"lfc_1w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"LFC\", 1, 2)\n",
    "        elif model_name == \"sfc_1w1a\":\n",
    "            pretrained_model = get_test_model_trained(\"SFC\", 1, 1)\n",
    "        elif model_name == \"sfc_1w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"SFC\", 1, 2)\n",
    "        elif model_name == \"sfc_2w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"SFC\", 2, 2)\n",
    "        elif model_name == \"tfc_1w1a\":\n",
    "            pretrained_model = get_test_model_trained(\"TFC\", 1, 1)\n",
    "        elif model_name == \"tfc_1w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"TFC\", 1, 2)\n",
    "        elif model_name == \"tfc_2w2a\":\n",
    "            pretrained_model = get_test_model_trained(\"TFC\", 2, 2)\n",
    "        elif model_name == \"quant_mobilenet_v1_4b\":\n",
    "            pretrained_model = get_test_model_trained(\"mobilenet\", 4, 4)\n",
    "    # List of common input shapes to test first (both square and non-square)\n",
    "    common_shapes = [\n",
    "        (1, initial_channels, 32, 32),  # Typical for many models\n",
    "        (1, initial_channels, 28, 28),  # Typical for many models\n",
    "        (1, initial_channels, 224, 224),  # Typical for many models\n",
    "        (1, initial_channels, 299, 299),  # For models like Inception\n",
    "        (1, initial_channels, 128, 128),  # Smaller size\n",
    "        (1, initial_channels, 256, 256),  # Larger square size\n",
    "        (1, initial_channels, 320, 240),  # Common non-square size\n",
    "        (1, initial_channels, 240, 320),  # Non-square (swapped dimensions)\n",
    "        (1, initial_channels, 256, 128),  # Non-square\n",
    "        (1, initial_channels, 128, 256),  # Non-square (swapped)\n",
    "    ]\n",
    "\n",
    "    # Try common shapes first\n",
    "    for shape in common_shapes:\n",
    "        try:\n",
    "            dummy_input = torch.rand(*shape)\n",
    "            pretrained_model(dummy_input)\n",
    "            log_message(f\"Compatible common input shape found: {shape}\")\n",
    "            return pretrained_model, shape\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "\n",
    "    # If no common shape worked, test all possible square and non-square shapes up to max_size\n",
    "    for width in range(1, max_size + 1, 1):  # Step by 16 for efficiency\n",
    "        for height in range(1, max_size + 1, 1):\n",
    "            try:\n",
    "                dummy_input = torch.rand(1, initial_channels, width, height)\n",
    "                pretrained_model(dummy_input)\n",
    "                pretrained_model_input_shape = (1, initial_channels, width, height)\n",
    "                log_message(f\"Compatible input shape found: {pretrained_model_input_shape}\")\n",
    "                return pretrained_model, pretrained_model_input_shape\n",
    "            except RuntimeError:\n",
    "                continue\n",
    "\n",
    "    log_message(\"Could not determine a compatible input shape within the specified range.\", level=\"error\")"
   ],
   "id": "e912d407f448ecb4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3b4a8b34b65b86a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T06:07:12.856104Z",
     "start_time": "2024-11-13T06:07:11.428651Z"
    }
   },
   "source": [
    "prj_name_input = \"AlexNet 1W1A Test\"\n",
    "board_name_input = \"Pynq-Z2\"\n",
    "prj_folder_input = sanitize_string(prj_name_input)\n",
    "model_type_input = \"torch_vision_pretrained\"\n",
    "torch_vision_model_input = \"alexnet\"\n",
    "Project_Info = setup_project(prj_name=prj_name_input, brd_name=board_name_input, model_type=model_type_input, torch_vision_model=torch_vision_model_input)\n",
    "\n",
    "input_model= None\n",
    "input_model_shape = None\n",
    "\n",
    "if Project_Info['Model_Type'] == \"untrained\":\n",
    "    log_message(\"Training for untrained models are not supported at the moment!\", level=\"error\")\n",
    "elif Project_Info['Model_Type'] == \"custom_pretrained\":\n",
    "    log_message(\"Custom Pretrained models are not supported at the moment!\", level=\"error\")\n",
    "elif Project_Info['Model_Type'] == \"torch_vision_pretrained\" or Project_Info['Model_Type'] == \"finn_pretrained\":\n",
    "    pretrained_folder = os.path.join(Project_Info['Folder'],\"src\")\n",
    "    input_model, input_model_shape = load_pretrained_model(Project_Info['Torch_Vision_Model'], Project_Info['Model_Type'], pretrained_folder)\n",
    "else:\n",
    "    log_message(\"Unsupported Model Type\", level=\"error\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Setting up project\n",
      "[INFO] Project setup complete. AlexNet 1W1A Test has been initialized.\n",
      "[INFO] Loading torch_vision_pretrained Model: alexnet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/fastqnn/finn/notebooks/Fast-QNN/outputs/txaviour/alexnet_1w1a_test_0/src/hub/pytorch_vision_v0.10.0\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compatible common input shape found: (1, 3, 224, 224)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:12:24.601384Z",
     "start_time": "2024-11-08T22:12:24.596235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def set_onnx_checkpoint(project_info, suffix):\n",
    "    \"\"\"\n",
    "    Generates the export path for ONNX files based on a specified suffix.\n",
    "\n",
    "    Parameters:\n",
    "        project_info (dict): Dictionary containing project information (e.g., 'Folder' and 'Stripped_Name').\n",
    "        suffix (str): The suffix to append to the exported ONNX filename (e.g., \"model1\" for \"model1_export.onnx\").\n",
    "\n",
    "    Returns:\n",
    "        str: The full path to the export file.\n",
    "    \"\"\"\n",
    "    log_message(f\"Saving Checkpoint: {suffix}\")\n",
    "    suffix = sanitize_string(suffix)\n",
    "    filename = f\"{project_info['Stripped_Name']}_{suffix}.onnx\"\n",
    "    return os.path.join(project_info['Folder'], \"checkpoints\", filename)\n"
   ],
   "id": "1f4ae7b982c2a64c",
   "outputs": [],
   "execution_count": 177
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-08T22:12:30.705675Z",
     "start_time": "2024-11-08T22:12:24.647528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "export_onnx_path = set_onnx_checkpoint(Project_Info,\"Brevitas Export\")\n",
    "export_qonnx(input_model, torch.randn(input_model_shape), export_onnx_path, opset_version=9)\n",
    "qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Brevitas Export\n"
     ]
    }
   ],
   "execution_count": 178
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:12:37.191848Z",
     "start_time": "2024-11-08T22:12:30.730067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "\n",
    "model = ModelWrapper(export_onnx_path)\n",
    "model = model.transform(ConvertQONNXtoFINN())\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"QONNX to FINN\"))"
   ],
   "id": "de436732503bc809",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: QONNX to FINN\n"
     ]
    }
   ],
   "execution_count": 179
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T22:12:37.231872Z",
     "start_time": "2024-11-08T22:12:37.223252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qonnx.transformation.double_to_single_float import DoubleToSingleFloat\n",
    "from qonnx.transformation.remove import RemoveIdentityOps\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (GiveReadableTensorNames,\n",
    "                                          GiveUniqueNodeNames,\n",
    "                                          RemoveStaticGraphInputs,\n",
    "                                          RemoveUnusedTensors, GiveUniqueParameterTensors, SortGraph)\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "\n",
    "def tidy_up_transforms(input_tidy_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a series of transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_tidy_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply transformations\n",
    "    input_tidy_model = input_tidy_model.transform(GiveUniqueParameterTensors())\n",
    "    input_tidy_model = input_tidy_model.transform(InferShapes())\n",
    "    input_tidy_model = input_tidy_model.transform(FoldConstants())\n",
    "    input_tidy_model = input_tidy_model.transform(GiveUniqueNodeNames())\n",
    "    input_tidy_model = input_tidy_model.transform(GiveReadableTensorNames())\n",
    "    input_tidy_model = input_tidy_model.transform(InferDataTypes())\n",
    "    input_tidy_model = input_tidy_model.transform(RemoveStaticGraphInputs())\n",
    "    input_tidy_model = input_tidy_model.transform(InferDataLayouts())\n",
    "    input_tidy_model = input_tidy_model.transform(RemoveUnusedTensors())\n",
    "    input_tidy_model = input_tidy_model.transform(DoubleToSingleFloat())\n",
    "    input_tidy_model = input_tidy_model.transform(SortGraph())\n",
    "    input_tidy_model = input_tidy_model.transform(RemoveIdentityOps())\n",
    "\n",
    "    # Save the transformed model\n",
    "    input_tidy_model.save(save_name)\n",
    "\n",
    "    return input_tidy_model"
   ],
   "id": "a5d959d6407a1ec2",
   "outputs": [],
   "execution_count": 180
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-11-08T22:12:37.256775Z"
    }
   },
   "cell_type": "code",
   "source": "model = tidy_up_transforms(model, set_onnx_checkpoint(Project_Info,\"Tidy ONNX Post Finn\"))",
   "id": "21fb27ba948a8cbd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving Checkpoint: Tidy ONNX Post Finn\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from finn.util.pytorch import ToTensor\n",
    "\n",
    "log_message(\"Skipping Pre-Processing. Will be expecting the user to handle it in application!\", level=\"warning\")"
   ],
   "id": "511d18741790a4a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = set_onnx_checkpoint(Project_Info,\"Pre Proc ONNX Finn\")\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\"\"\""
   ],
   "id": "57af62ce8ef3c010",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"Post Processing\"))\n",
    "model = tidy_up_transforms(model, set_onnx_checkpoint(Project_Info,\"Tidy Post PrePost Proc\"))"
   ],
   "id": "49bbd723443c4e65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from onnx import TensorProto\n",
    "from qonnx.transformation.base import Transformation\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "\n",
    "class CustomReluBreakdown(Transformation):\n",
    "    \"\"\"Replace ReLU nodes with an equivalent series of simpler ONNX operations.\"\"\"\n",
    "\n",
    "    def apply(self, transform_model):\n",
    "        graph = transform_model.graph\n",
    "        node_ind = 0\n",
    "        graph_modified = False\n",
    "        for n in graph.node:\n",
    "            node_ind += 1\n",
    "            if n.op_type == \"Relu\":\n",
    "                # Get the input and output names\n",
    "                input_name = n.input[0]\n",
    "                output_name = n.output[0]\n",
    "\n",
    "                # Create a constant tensor for zero\n",
    "                zero_const_name = f\"{n.name}_zero_const\"\n",
    "                zero_tensor = oh.make_tensor(\n",
    "                    zero_const_name,  # Name of the constant tensor\n",
    "                    TensorProto.FLOAT,  # Data type\n",
    "                    dims=[1],  # Shape of the tensor\n",
    "                    vals=[0.0]  # Value of the tensor\n",
    "                )\n",
    "                transform_model.graph.initializer.append(zero_tensor)\n",
    "\n",
    "                # Create the Max node that mimics ReLU behavior\n",
    "                max_node = oh.make_node(\n",
    "                    \"Max\",\n",
    "                    inputs=[input_name, zero_const_name],\n",
    "                    outputs=[output_name],\n",
    "                    name=f\"{n.name}_max\"\n",
    "                )\n",
    "\n",
    "                # Insert the Max node into the graph\n",
    "                graph.node.insert(node_ind, max_node)\n",
    "\n",
    "                # Remove the original ReLU node\n",
    "                graph.node.remove(n)\n",
    "                graph_modified = True\n",
    "\n",
    "        # Infer shapes after modifying the graph\n",
    "        transform_model = transform_model.transform(InferShapes())\n",
    "        return (transform_model, graph_modified)"
   ],
   "id": "a45466c16fde453c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from onnx import helper as oh\n",
    "from onnx import TensorProto\n",
    "\n",
    "class ReplaceMaxWithArithmetic(Transformation):\n",
    "    \"\"\"\n",
    "    Custom transformation to replace 'Max' nodes with a series of operations\n",
    "    using addition, subtraction, absolute value, and division.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(self, transform_model):\n",
    "        graph = transform_model.graph\n",
    "        graph_modified = False\n",
    "\n",
    "        for node in graph.node:\n",
    "            if node.op_type == \"Max\":\n",
    "                # Check if the node has exactly 2 inputs for binary Max operation\n",
    "                if len(node.input) == 2:\n",
    "                    max_input_1 = node.input[0]\n",
    "                    max_input_2 = node.input[1]\n",
    "                    max_output = node.output[0]\n",
    "\n",
    "                    # Create intermediate nodes to simulate the Max operation\n",
    "                    # Create a node for computing (input_1 - input_2)\n",
    "                    diff_output = max_output + \"_diff\"\n",
    "                    diff_node = oh.make_node(\n",
    "                        \"Sub\", [max_input_1, max_input_2], [diff_output], name=max_output + \"_sub\"\n",
    "                    )\n",
    "\n",
    "                    # Create a node for computing (abs(input_1 - input_2))\n",
    "                    abs_output = max_output + \"_abs\"\n",
    "                    abs_node = oh.make_node(\n",
    "                        \"Abs\", [diff_output], [abs_output], name=max_output + \"_abs\"\n",
    "                    )\n",
    "\n",
    "                    # Create a node for computing (input_1 + input_2)\n",
    "                    sum_inputs_output = max_output + \"_sum_inputs\"\n",
    "                    sum_inputs_node = oh.make_node(\n",
    "                        \"Add\", [max_input_1, max_input_2], [sum_inputs_output], name=max_output + \"_sum_inputs\"\n",
    "                    )\n",
    "\n",
    "                    # Create a node for computing ((input_1 + input_2) + abs(input_1 - input_2))\n",
    "                    final_sum_output = max_output + \"_final_sum\"\n",
    "                    final_sum_node = oh.make_node(\n",
    "                        \"Add\", [sum_inputs_output, abs_output], [final_sum_output], name=max_output + \"_final_sum\"\n",
    "                    )\n",
    "\n",
    "                    # Create a constant tensor for the value 2 and add it to the model's initializers\n",
    "                    const_two_name = max_output + \"_const_two\"\n",
    "                    const_two = oh.make_tensor(\n",
    "                        name=const_two_name,\n",
    "                        data_type=TensorProto.FLOAT,\n",
    "                        dims=[],\n",
    "                        vals=[2.0]\n",
    "                    )\n",
    "                    transform_model.graph.initializer.append(const_two)\n",
    "\n",
    "                    # Create a node for the division to get the final max output\n",
    "                    div_node = oh.make_node(\n",
    "                        \"Div\", [final_sum_output, const_two_name], [max_output], name=max_output + \"_div\"\n",
    "                    )\n",
    "\n",
    "                    # Insert new nodes into the graph\n",
    "                    graph.node.extend([diff_node, abs_node, sum_inputs_node, final_sum_node, div_node])\n",
    "\n",
    "                    # Remove the original Max node\n",
    "                    graph.node.remove(node)\n",
    "                    graph_modified = True\n",
    "\n",
    "        transform_model = transform_model.transform(InferShapes())\n",
    "        return (transform_model, graph_modified)"
   ],
   "id": "6f10b8949cef84a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from onnx import helper as oh, TensorProto\n",
    "from qonnx.transformation.base import Transformation\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "\n",
    "class ReplaceAbsWithLinearArithmeticNoBranching(Transformation):\n",
    "    \"\"\"\n",
    "    Custom transformation to replace 'Abs' nodes with a linear sequence of arithmetic operations\n",
    "    without branching.\n",
    "    \"\"\"\n",
    "\n",
    "    def apply(self, transform_model):\n",
    "        graph = transform_model.graph\n",
    "        graph_modified = False\n",
    "\n",
    "        for node in graph.node:\n",
    "            if node.op_type == \"Abs\":\n",
    "                # Check if the node has exactly 1 input for Abs operation\n",
    "                abs_input = node.input[0]\n",
    "                abs_output = node.output[0]\n",
    "\n",
    "                # Create unique names for the intermediate outputs\n",
    "                neg_output = abs_output + \"_neg\"\n",
    "                add_output = abs_output + \"_add\"\n",
    "                mul_output = abs_output + \"_mul\"\n",
    "\n",
    "                # Create a node for computing (input * -1)\n",
    "                neg_node = oh.make_node(\n",
    "                    \"Mul\", [abs_input, abs_output + \"_const_neg1\"], [neg_output], name=abs_output + \"_mul_neg\"\n",
    "                )\n",
    "\n",
    "                # Create a constant tensor for -1\n",
    "                const_neg_one = oh.make_tensor(\n",
    "                    name=abs_output + \"_const_neg1\",\n",
    "                    data_type=TensorProto.FLOAT,\n",
    "                    dims=[],\n",
    "                    vals=[-1.0]\n",
    "                )\n",
    "                transform_model.graph.initializer.append(const_neg_one)\n",
    "\n",
    "                # Create a node for computing (input + neg_input)\n",
    "                add_node = oh.make_node(\n",
    "                    \"Add\", [abs_input, neg_output], [add_output], name=abs_output + \"_add\"\n",
    "                )\n",
    "\n",
    "                # Create a node for computing ((input + neg_input) * 0.5)\n",
    "                mul_node = oh.make_node(\n",
    "                    \"Mul\", [add_output, abs_output + \"_const_0.5\"], [mul_output], name=abs_output + \"_mul_half\"\n",
    "                )\n",
    "\n",
    "                # Create a constant tensor for 0.5\n",
    "                const_half = oh.make_tensor(\n",
    "                    name=abs_output + \"_const_0.5\",\n",
    "                    data_type=TensorProto.FLOAT,\n",
    "                    dims=[],\n",
    "                    vals=[0.5]\n",
    "                )\n",
    "                transform_model.graph.initializer.append(const_half)\n",
    "\n",
    "                # Rename the final output to match the original Abs output\n",
    "                final_node = oh.make_node(\n",
    "                    \"Identity\", [mul_output], [abs_output], name=abs_output + \"_identity\"\n",
    "                )\n",
    "\n",
    "                # Insert the new nodes into the graph\n",
    "                graph.node.extend([neg_node, add_node, mul_node, final_node])\n",
    "\n",
    "                # Remove the original Abs node\n",
    "                graph.node.remove(node)\n",
    "                graph_modified = True\n",
    "\n",
    "        transform_model = transform_model.transform(InferShapes())\n",
    "        return (transform_model, graph_modified)\n"
   ],
   "id": "2d8a18afa0cb7e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from qonnx.transformation.batchnorm_to_affine import BatchNormToAffine\n",
    "from qonnx.transformation.general import ConvertSubToAdd, ConvertDivToMul\n",
    "from finn.transformation.streamline import Streamline, RoundAndClipThresholds, CollapseRepeatedMul, ConvertSignToThres, \\\n",
    "    CollapseRepeatedAdd\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.absorb import (AbsorbTransposeIntoMultiThreshold,\n",
    "                                                   AbsorbScalarMulAddIntoTopK,\n",
    "                                                   AbsorbSignBiasIntoMultiThreshold,\n",
    "                                                   AbsorbAddIntoMultiThreshold,\n",
    "                                                   AbsorbMulIntoMultiThreshold, FactorOutMulSignMagnitude,\n",
    "                                                   Absorb1BitMulIntoMatMul, Absorb1BitMulIntoConv)\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants, MoveAddPastMul, \\\n",
    "    MoveScalarAddPastMatMul, MoveAddPastConv, MoveScalarMulPastMatMul, MoveScalarMulPastConv, \\\n",
    "    MoveMaxPoolPastMultiThreshold, MoveLinearPastEltwiseAdd, MoveLinearPastFork\n",
    "from finn.transformation.streamline.absorb import AbsorbConsecutiveTransposes\n",
    "\n",
    "def streamline_transforms(input_streamline_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a series of streamlining transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_streamline_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "    for iter_id in range(5):\n",
    "        # Apply streamlining transformations    \n",
    "        input_streamline_model = input_streamline_model.transform(CustomReluBreakdown())\n",
    "        input_streamline_model = input_streamline_model.transform(ReplaceMaxWithArithmetic())\n",
    "        input_streamline_model = input_streamline_model.transform(ReplaceAbsWithLinearArithmeticNoBranching())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbSignBiasIntoMultiThreshold())\n",
    "        \n",
    "        input_streamline_model = input_streamline_model.transform(ConvertSubToAdd())\n",
    "        input_streamline_model = input_streamline_model.transform(ConvertDivToMul())\n",
    "        input_streamline_model = input_streamline_model.transform(CollapseRepeatedMul())\n",
    "        input_streamline_model = input_streamline_model.transform(BatchNormToAffine())\n",
    "        input_streamline_model = input_streamline_model.transform(ConvertSignToThres())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveAddPastMul())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveScalarAddPastMatMul())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveAddPastConv())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveScalarMulPastMatMul())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveScalarMulPastConv())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveAddPastMul())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveScalarLinearPastInvariants())\n",
    "        input_streamline_model = input_streamline_model.transform(CollapseRepeatedAdd())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbAddIntoMultiThreshold())\n",
    "        input_streamline_model = input_streamline_model.transform(FactorOutMulSignMagnitude())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveMaxPoolPastMultiThreshold())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbMulIntoMultiThreshold())\n",
    "        input_streamline_model = input_streamline_model.transform(Absorb1BitMulIntoMatMul())\n",
    "        input_streamline_model = input_streamline_model.transform(Absorb1BitMulIntoConv())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbMulIntoMultiThreshold())\n",
    "        \n",
    "        input_streamline_model = input_streamline_model.transform(Streamline())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbConsecutiveTransposes())\n",
    "        input_streamline_model = input_streamline_model.transform(LowerConvsToMatMul())\n",
    "        input_streamline_model = input_streamline_model.transform(MakeMaxPoolNHWC())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbTransposeIntoMultiThreshold())\n",
    "        input_streamline_model = input_streamline_model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "        input_streamline_model = input_streamline_model.transform(Streamline())\n",
    "        input_streamline_model = input_streamline_model.transform(AbsorbScalarMulAddIntoTopK())\n",
    "        input_streamline_model = input_streamline_model.transform(RoundAndClipThresholds())\n",
    "        \n",
    "        input_streamline_model = input_streamline_model.transform(MoveLinearPastEltwiseAdd())\n",
    "        input_streamline_model = input_streamline_model.transform(MoveLinearPastFork())\n",
    "        # Save the transformed model after tidying up\n",
    "        input_streamline_model = tidy_up_transforms(input_streamline_model, save_name)\n",
    "    \n",
    "\n",
    "    #need_lowering = len(model.get_nodes_by_op_type(\"Conv\")) > 0\n",
    "    #if need_lowering:\n",
    "    #    do transforms\n",
    "    #    model = model.transform(MakeMaxPoolNHWC()) # how to handle repeats that are required. use the ifs?\n",
    "\n",
    "\n",
    "    return input_streamline_model"
   ],
   "id": "6bdb92934093ceb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = streamline_transforms(model, set_onnx_checkpoint(Project_Info,\"Streamlined ONNX\"))",
   "id": "d969950c0d96fc53",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.fpgadataflow.convert_to_hw_layers import (\n",
    "    InferBinaryMatrixVectorActivation,\n",
    "    InferQuantizedMatrixVectorActivation,\n",
    "    InferLabelSelectLayer,\n",
    "    InferThresholdingLayer,\n",
    "    InferStreamingMaxPool,\n",
    "    InferConvInpGen,\n",
    "    InferAddStreamsLayer,\n",
    "    InferChannelwiseLinearLayer,\n",
    "    InferConcatLayer,\n",
    "    InferDuplicateStreamsLayer,\n",
    "    InferGlobalAccPoolLayer,\n",
    "    InferLookupLayer,\n",
    "    InferPool,\n",
    "    InferStreamingEltwise,\n",
    "    InferUpsample,\n",
    "    InferVectorVectorActivation\n",
    ")\n",
    "\n",
    "def to_hw_transforms(input_hw_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies a comprehensive series of hardware-oriented transformations to a model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_hw_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The path to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model.\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply a comprehensive list of hardware transformations\n",
    "    input_hw_model = input_hw_model.transform(InferBinaryMatrixVectorActivation())\n",
    "    input_hw_model = input_hw_model.transform(InferQuantizedMatrixVectorActivation())\n",
    "    input_hw_model = input_hw_model.transform(InferLabelSelectLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferThresholdingLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferConvInpGen())\n",
    "    input_hw_model = input_hw_model.transform(InferStreamingMaxPool())\n",
    "    input_hw_model = input_hw_model.transform(InferAddStreamsLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferChannelwiseLinearLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferConcatLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferDuplicateStreamsLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferGlobalAccPoolLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferLookupLayer())\n",
    "    input_hw_model = input_hw_model.transform(InferPool())\n",
    "    input_hw_model = input_hw_model.transform(InferStreamingEltwise())\n",
    "    input_hw_model = input_hw_model.transform(InferUpsample())\n",
    "    input_hw_model = input_hw_model.transform(InferVectorVectorActivation())\n",
    "    \n",
    "    input_hw_model = input_hw_model.transform(RemoveCNVtoFCFlatten())\n",
    "    input_hw_model = input_hw_model.transform(AbsorbConsecutiveTransposes())\n",
    "\n",
    "    # Apply final tidy-up transformations\n",
    "    input_hw_model = tidy_up_transforms(input_hw_model, save_name)\n",
    "\n",
    "    # Save the final transformed model\n",
    "    input_hw_model.save(save_name)\n",
    "\n",
    "    return input_hw_model"
   ],
   "id": "e34005da6e651b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = to_hw_transforms(model, set_onnx_checkpoint(Project_Info,\"To HW Layers\"))",
   "id": "3231949dbb03adb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "\n",
    "def dataflow_partitioning(input_data_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies dataflow partitioning transformation to the model and saves the resulting parent and dataflow models.\n",
    "\n",
    "    Parameters:\n",
    "        input_data_model (ModelWrapper): The model to transform.\n",
    "        save_name (str): The directory to save the transformed models.\n",
    "\n",
    "    Returns:\n",
    "        ModelWrapper: The transformed parent model.\n",
    "    \"\"\"\n",
    "    # Apply dataflow partitioning\n",
    "    parent_model = input_data_model.transform(CreateDataflowPartition())\n",
    "    parent_model.save(save_name)\n",
    "    \n",
    "    # Retrieve the dataflow partition model filename\n",
    "    sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "    sdp_node = getCustomOp(sdp_node)\n",
    "    dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "    # Load and return the dataflow model\n",
    "    dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "    \n",
    "    return dataflow_model"
   ],
   "id": "7b896786bf7eccae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = dataflow_partitioning(model, set_onnx_checkpoint(Project_Info,\"Dataflow Partition Parent Model\"))\n",
    "model.save(set_onnx_checkpoint(Project_Info,\"Dataflow Partition Streaming Model\"))"
   ],
   "id": "a18f4bf215064d2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "\n",
    "def specialize_layers_transform(input_specialize_model, board_name, save_name):\n",
    "    \"\"\"\n",
    "    Applies layer specialization transformation to a dataflow model for the specified FPGA part and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_specialize_model (ModelWrapper): The dataflow model to transform.\n",
    "        board_name (str): The FPGA board for which to specialize the layers.\n",
    "        save_name (str): The path to save the specialized model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed and specialized dataflow model.\n",
    "    \"\"\"\n",
    "    fpga_part = pynq_part_map[board_name]\n",
    "    # Apply specialization for FPGA layers\n",
    "    input_specialize_model = input_specialize_model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "    # Save the specialized model\n",
    "    input_specialize_model.save(save_name)\n",
    "\n",
    "    return input_specialize_model"
   ],
   "id": "29068574207cfe2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = specialize_layers_transform(model, Project_Info['Board_name'], set_onnx_checkpoint(Project_Info,f\"Specialize Model Layers to {Project_Info['Board_name']}\"))",
   "id": "66573cba9e8b29aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def folding_transform(input_folding_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies folding configuration to fully connected (MVAU_hls) and sliding window (ConvolutionInputGenerator_rtl)\n",
    "    layers in the model and saves the resulting model.\n",
    "\n",
    "    Parameters:\n",
    "        input_folding_model (ModelWrapper): The specialized model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed and folded dataflow model.\n",
    "    \"\"\"\n",
    "    folding_config = [\n",
    "    (16, 3, [128]),\n",
    "    (32, 32, [128]),\n",
    "    (16, 32, [128]),\n",
    "    (16, 32, [128]),\n",
    "    (4, 32, [81]),\n",
    "    (1, 32, [2]),\n",
    "    (1, 4, [2]),\n",
    "    (1, 8, [128]),\n",
    "    (5, 1, [3]),\n",
    "    ]\n",
    "    \n",
    "    # Apply folding configuration to fully connected layers\n",
    "    fc_layers = input_folding_model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "    for fcl, (pe, simd, ififodepth) in zip(fc_layers, folding_config):\n",
    "        fcl_inst = getCustomOp(fcl)\n",
    "        fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "        fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "        fcl_inst.set_nodeattr(\"inFIFODepths\", ififodepth)\n",
    "    \n",
    "    # Apply SIMD values from the folding configuration to sliding window layers\n",
    "    swg_layers = input_folding_model.get_nodes_by_op_type(\"ConvolutionInputGenerator_rtl\")\n",
    "    for i in range(len(swg_layers)):\n",
    "        swg_inst = getCustomOp(swg_layers[i])\n",
    "        simd = folding_config[i][1]\n",
    "        swg_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    \n",
    "    # Apply unique node names to all nodes and save the transformed model\n",
    "    input_folding_model = input_folding_model.transform(GiveUniqueNodeNames())\n",
    "    input_folding_model.save(save_name)\n",
    "\n",
    "    return input_folding_model\n"
   ],
   "id": "cd5527c3889d3ed2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = folding_transform(model, set_onnx_checkpoint(Project_Info, \"Folded Model\"))",
   "id": "1269bd96fdeb9db3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "\n",
    "def zynq_build_transform(input_zynq_model, save_name, brd_name):\n",
    "    \"\"\"\n",
    "    Applies the ZynqBuild transformation to a model for the specified PYNQ board and clock period.\n",
    "\n",
    "    Parameters:\n",
    "        input_zynq_model (ModelWrapper): Folded model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "        brd_name (str): Name of the PYNQ board to target.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model after applying ZynqBuild.\n",
    "    \"\"\"\n",
    "    target_clk_ns = 10\n",
    "    # Apply ZynqBuild transformation\n",
    "    input_zynq_model = input_zynq_model.transform(ZynqBuild(platform=brd_name, period_ns=target_clk_ns))\n",
    "    \n",
    "    # Save the transformed model\n",
    "    input_zynq_model.save(save_name)\n",
    "\n",
    "    return input_zynq_model\n"
   ],
   "id": "394bed78132471e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "\n",
    "def pynq_driver_transform(input_driver_model, save_name):\n",
    "    \"\"\"\n",
    "    Applies the MakePYNQDriver transformation to the model to generate a PYNQ-compatible driver.\n",
    "\n",
    "    Parameters:\n",
    "        input_driver_model (ModelWrapper): ZynqBuild model to transform.\n",
    "        save_name (str): Directory to save the transformed model.\n",
    "    \n",
    "    Returns:\n",
    "        ModelWrapper: The transformed model with PYNQ driver compatibility.\n",
    "    \"\"\"\n",
    "    # Apply MakePYNQDriver transformation\n",
    "    input_driver_model = input_driver_model.transform(MakePYNQDriver(\"zynq-iodma\"))\n",
    "    \n",
    "    # Save the transformed model\n",
    "    input_driver_model.save(save_name)\n",
    "\n",
    "    return input_driver_model\n"
   ],
   "id": "d1f6d7caa00a8452",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = zynq_build_transform(model, set_onnx_checkpoint(Project_Info, \"Zynq Build\"), Project_Info['Board_name'])\n",
    "model = pynq_driver_transform(model, set_onnx_checkpoint(Project_Info, \"Pynq Driver\"))"
   ],
   "id": "669b7375d6509996",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
