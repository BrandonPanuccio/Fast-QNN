{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# FINN - End-to-End Flow\n",
    "-----------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:05:55.505581Z",
     "start_time": "2024-10-08T23:05:55.494937Z"
    }
   },
   "source": [
    "from finn.util.visualization import showSrc, showInNetron\n",
    "from finn.util.basic import make_build_dir\n",
    "import os\n",
    "    \n",
    "build_dir = \"Fast-QNN/outputs/initial\""
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:05:57.653001Z",
     "start_time": "2024-10-08T23:05:56.845148Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "\n",
    "tfc = get_test_model_trained(\"TFC\", 1, 1)\n",
    "export_onnx_path = build_dir+\"/tfc_w1_a1.onnx\"\n",
    "export_qonnx(tfc, torch.randn(1, 1, 28, 28), build_dir+\"/tfc_w1_a1.onnx\") # semicolon added to suppress log\n",
    "qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:06:00.948318Z",
     "start_time": "2024-10-08T23:06:00.857403Z"
    }
   },
   "source": "showInNetron(build_dir+\"/tfc_w1_a1.onnx\")",
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "No opset import for domain 'qonnx.custom_op.general'\n\n==> Context: Bad node spec for node. Name: BipolarQuant_0 OpType: BipolarQuant",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m onnx\u001B[38;5;241m.\u001B[39mload(build_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tfc_w1_a1.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43monnx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchecker\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m)\u001B[38;5;66;03m# semicolon added to suppress log\u001B[39;00m\n\u001B[1;32m      3\u001B[0m showInNetron(build_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tfc_w1_a1.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/usr/local/lib/python3.10/dist-packages/onnx/checker.py:179\u001B[0m, in \u001B[0;36mcheck_model\u001B[0;34m(model, full_check, skip_opset_compatibility_check, check_custom_domain)\u001B[0m\n\u001B[1;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39mgetsizeof(protobuf_string) \u001B[38;5;241m>\u001B[39m MAXIMUM_PROTOBUF:\n\u001B[1;32m    176\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    177\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis protobuf of onnx model is too large (>2GB). Call check_model with model path instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    178\u001B[0m     )\n\u001B[0;32m--> 179\u001B[0m \u001B[43mC\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprotobuf_string\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfull_check\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[43m    \u001B[49m\u001B[43mskip_opset_compatibility_check\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    183\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcheck_custom_domain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    184\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValidationError\u001B[0m: No opset import for domain 'qonnx.custom_op.general'\n\n==> Context: Bad node spec for node. Name: BipolarQuant_0 OpType: BipolarQuant"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:32:45.485260Z",
     "start_time": "2024-10-08T22:32:45.160026Z"
    }
   },
   "source": [
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1_a1.onnx\")\n",
    "model = model.transform(ConvertQONNXtoFINN())"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:32:48.433691Z",
     "start_time": "2024-10-08T22:32:48.200108Z"
    }
   },
   "source": [
    "model.save(build_dir+\"/tfc_w1_a1_finn.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_finn.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_finn.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x79933a91be80>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:33:39.898906Z",
     "start_time": "2024-10-08T22:33:39.752176Z"
    }
   },
   "source": [
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "model.save(build_dir+\"/tfc_w1_a1_tidy.onnx\")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:33:46.635822Z",
     "start_time": "2024-10-08T22:33:46.446673Z"
    }
   },
   "source": [
    "showInNetron(build_dir+\"/tfc_w1_a1_tidy.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_tidy.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993309d95a0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:34:21.899887Z",
     "start_time": "2024-10-08T22:34:21.484454Z"
    }
   },
   "source": [
    "from finn.util.pytorch import ToTensor\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.core.datatype import DataType\n",
    "\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1_a1_tidy.onnx\")\n",
    "global_inp_name = model.graph.input[0].name\n",
    "ishape = model.get_tensor_shape(global_inp_name)\n",
    "# preprocessing: torchvision's ToTensor divides uint8 inputs by 255\n",
    "totensor_pyt = ToTensor()\n",
    "chkpt_preproc_name = build_dir+\"/tfc_w1_a1_preproc.onnx\"\n",
    "export_qonnx(totensor_pyt, torch.randn(ishape), chkpt_preproc_name)\n",
    "qonnx_cleanup(chkpt_preproc_name, out_file=chkpt_preproc_name)\n",
    "pre_model = ModelWrapper(chkpt_preproc_name)\n",
    "pre_model = pre_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "# join preprocessing and core model\n",
    "model = model.transform(MergeONNXModels(pre_model))\n",
    "# add input quantization annotation: UINT8 for all BNN-PYNQ models\n",
    "global_inp_name = model.graph.input[0].name\n",
    "model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "model.save(build_dir+\"/tfc_w1_a1_with_preproc.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_with_preproc.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/home_dir/.local/lib/python3.10/site-packages/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_with_preproc.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3d1fa00>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:35:13.202803Z",
     "start_time": "2024-10-08T22:35:12.868819Z"
    }
   },
   "source": [
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "\n",
    "# postprocessing: insert Top-1 node at the end\n",
    "model = model.transform(InsertTopK(k=1))\n",
    "chkpt_name = build_dir+\"/tfc_w1_a1_pre_post.onnx\"\n",
    "# tidy-up again\n",
    "model = model.transform(InferShapes())\n",
    "model = model.transform(FoldConstants())\n",
    "model = model.transform(GiveUniqueNodeNames())\n",
    "model = model.transform(GiveReadableTensorNames())\n",
    "model = model.transform(InferDataTypes())\n",
    "model = model.transform(RemoveStaticGraphInputs())\n",
    "model.save(chkpt_name)\n",
    "\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_pre_post.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_pre_post.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3db7940>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:35:22.240489Z",
     "start_time": "2024-10-08T22:35:22.156674Z"
    }
   },
   "source": [
    "from finn.transformation.streamline import Streamline\n",
    "showSrc(Streamline)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class Streamline(Transformation):\n",
      "    \"\"\"Apply the streamlining transform, see arXiv:1709.04060.\"\"\"\n",
      "\n",
      "    def apply(self, model):\n",
      "        streamline_transformations = [\n",
      "            ConvertSubToAdd(),\n",
      "            ConvertDivToMul(),\n",
      "            BatchNormToAffine(),\n",
      "            ConvertSignToThres(),\n",
      "            MoveMulPastMaxPool(),\n",
      "            MoveScalarLinearPastInvariants(),\n",
      "            AbsorbSignBiasIntoMultiThreshold(),\n",
      "            MoveAddPastMul(),\n",
      "            MoveScalarAddPastMatMul(),\n",
      "            MoveAddPastConv(),\n",
      "            MoveScalarMulPastMatMul(),\n",
      "            MoveScalarMulPastConv(),\n",
      "            MoveAddPastMul(),\n",
      "            CollapseRepeatedAdd(),\n",
      "            CollapseRepeatedMul(),\n",
      "            MoveMulPastMaxPool(),\n",
      "            AbsorbAddIntoMultiThreshold(),\n",
      "            FactorOutMulSignMagnitude(),\n",
      "            AbsorbMulIntoMultiThreshold(),\n",
      "            Absorb1BitMulIntoMatMul(),\n",
      "            Absorb1BitMulIntoConv(),\n",
      "            RoundAndClipThresholds(),\n",
      "        ]\n",
      "        for trn in streamline_transformations:\n",
      "            model = model.transform(trn)\n",
      "            model = model.transform(RemoveIdentityOps())\n",
      "            model = model.transform(GiveUniqueNodeNames())\n",
      "            model = model.transform(GiveReadableTensorNames())\n",
      "            model = model.transform(InferDataTypes())\n",
      "        return (model, False)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:35:37.838201Z",
     "start_time": "2024-10-08T22:35:34.274676Z"
    }
   },
   "source": [
    "from finn.transformation.streamline.reorder import MoveScalarLinearPastInvariants\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1_a1_pre_post.onnx\")\n",
    "# move initial Mul (from preproc) past the Reshape\n",
    "model = model.transform(MoveScalarLinearPastInvariants())\n",
    "# streamline\n",
    "model = model.transform(Streamline())\n",
    "model.save(build_dir+\"/tfc_w1_a1_streamlined.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_streamlined.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_streamlined.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3df52d0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:36:00.413757Z",
     "start_time": "2024-10-08T22:36:00.281240Z"
    }
   },
   "source": [
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "\n",
    "model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "# absorb final add-mul nodes into TopK\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "# bit of tidy-up\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "model.save(build_dir+\"/tfc_w1a1_ready_for_hw_conversion.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1a1_ready_for_hw_conversion.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1a1_ready_for_hw_conversion.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3c76380>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:36:22.321358Z",
     "start_time": "2024-10-08T22:36:22.139122Z"
    }
   },
   "source": [
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1a1_ready_for_hw_conversion.onnx\")\n",
    "model = model.transform(to_hw.InferBinaryMatrixVectorActivation())\n",
    "# TopK to LabelSelect\n",
    "model = model.transform(to_hw.InferLabelSelectLayer())\n",
    "# input quantization (if any) to standalone thresholding\n",
    "model = model.transform(to_hw.InferThresholdingLayer())\n",
    "model.save(build_dir+\"/tfc_w1_a1_hw_layers.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_hw_layers.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_hw_layers.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3c77a90>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:37:12.083432Z",
     "start_time": "2024-10-08T22:37:12.007481Z"
    }
   },
   "source": [
    "from finn.transformation.fpgadataflow.create_dataflow_partition import CreateDataflowPartition\n",
    "\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1_a1_hw_layers.onnx\")\n",
    "parent_model = model.transform(CreateDataflowPartition())\n",
    "parent_model.save(build_dir+\"/tfc_w1_a1_dataflow_parent.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_dataflow_parent.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_dataflow_parent.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3b7b010>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:37:54.057764Z",
     "start_time": "2024-10-08T22:37:53.890144Z"
    }
   },
   "source": [
    "from qonnx.custom_op.registry import getCustomOp\n",
    "sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "sdp_node = getCustomOp(sdp_node)\n",
    "dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "showInNetron(dataflow_model_filename)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/tmp/finn_dev_fastqnn/dataflow_partition_ic9_wxac/partition_0.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3b7bb50>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:38:02.121004Z",
     "start_time": "2024-10-08T22:38:02.106129Z"
    }
   },
   "source": [
    "model = ModelWrapper(dataflow_model_filename)"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:38:03.924904Z",
     "start_time": "2024-10-08T22:38:03.916013Z"
    }
   },
   "source": [
    "thresh_node = model.get_nodes_by_op_type(\"Thresholding\")[0]\n",
    "thresh_node_inst = getCustomOp(thresh_node)\n",
    "thresh_node_inst.set_nodeattr(\"preferred_impl_style\", \"hls\")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:38:08.233722Z",
     "start_time": "2024-10-08T22:38:08.224794Z"
    }
   },
   "source": [
    "# print the names of the supported PYNQ boards\n",
    "from finn.util.basic import pynq_part_map\n",
    "print(pynq_part_map.keys())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Ultra96', 'Ultra96-V2', 'Pynq-Z1', 'Pynq-Z2', 'ZCU102', 'ZCU104', 'ZCU111', 'RFSoC2x2', 'RFSoC4x2', 'KV260_SOM'])\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:38:15.014142Z",
     "start_time": "2024-10-08T22:38:15.004622Z"
    }
   },
   "source": [
    "# change this if you have a different PYNQ board, see list above\n",
    "pynq_board = \"Pynq-Z2\"\n",
    "fpga_part = pynq_part_map[pynq_board]\n",
    "target_clk_ns = 10"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:39:18.703998Z",
     "start_time": "2024-10-08T22:39:18.606360Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "model = model.transform(SpecializeLayers(fpga_part))\n",
    "\n",
    "model.save(build_dir+\"/tfc_w1_a1_specialize_layers.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_specialize_layers.onnx\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'Fast-QNN/outputs/initial/tfc_w1_a1_specialize_layers.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7993e3db6dd0>"
      ],
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:39:26.500015Z",
     "start_time": "2024-10-08T22:39:26.465185Z"
    }
   },
   "source": [
    "fc0 = model.graph.node[1]\n",
    "fc0w = getCustomOp(fc0)\n",
    "\n",
    "print(\"CustomOp wrapper is of class \" + fc0w.__class__.__name__)\n",
    "\n",
    "fc0w.get_nodeattr_types()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomOp wrapper is of class MVAU_hls\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PE': ('i', True, 0),\n",
       " 'SIMD': ('i', True, 0),\n",
       " 'MW': ('i', True, 0),\n",
       " 'MH': ('i', True, 0),\n",
       " 'resType': ('s', False, 'auto', {'auto', 'dsp', 'lut'}),\n",
       " 'ActVal': ('i', False, 0),\n",
       " 'inputDataType': ('s', True, ''),\n",
       " 'weightDataType': ('s', True, ''),\n",
       " 'outputDataType': ('s', True, ''),\n",
       " 'accDataType': ('s', False, 'INT32'),\n",
       " 'binaryXnorMode': ('i', False, 0, {0, 1}),\n",
       " 'noActivation': ('i', False, 0, {0, 1}),\n",
       " 'numInputVectors': ('ints', False, [1]),\n",
       " 'mem_mode': ('s',\n",
       "  False,\n",
       "  'internal_decoupled',\n",
       "  {'external', 'internal_decoupled', 'internal_embedded'}),\n",
       " 'ram_style': ('s', False, 'auto', {'auto', 'block', 'distributed', 'ultra'}),\n",
       " 'ram_style_thresholds': ('s',\n",
       "  False,\n",
       "  'auto',\n",
       "  {'auto', 'block', 'distributed'}),\n",
       " 'runtime_writeable_weights': ('i', False, 0, {0, 1}),\n",
       " 'backend': ('s', True, 'fpgadataflow'),\n",
       " 'preferred_impl_style': ('s', False, '', {'', 'hls', 'rtl'}),\n",
       " 'code_gen_dir_ipgen': ('s', False, ''),\n",
       " 'ipgen_path': ('s', False, ''),\n",
       " 'ip_path': ('s', False, ''),\n",
       " 'ip_vlnv': ('s', False, ''),\n",
       " 'exec_mode': ('s', False, '', {'', 'cppsim', 'rtlsim'}),\n",
       " 'cycles_rtlsim': ('i', False, 0),\n",
       " 'cycles_estimate': ('i', False, 0),\n",
       " 'rtlsim_trace': ('s', False, ''),\n",
       " 'res_estimate': ('s', False, ''),\n",
       " 'res_synth': ('s', False, ''),\n",
       " 'rtlsim_so': ('s', False, ''),\n",
       " 'slr': ('i', False, -1),\n",
       " 'mem_port': ('s', False, ''),\n",
       " 'partition_id': ('i', False, 0),\n",
       " 'device_id': ('i', False, 0),\n",
       " 'inFIFODepths': ('ints', False, [2]),\n",
       " 'outFIFODepths': ('ints', False, [2]),\n",
       " 'output_hook': ('s', False, ''),\n",
       " 'io_chrc_in': ('t', False, array([], dtype=int32)),\n",
       " 'io_chrc_out': ('t', False, array([], dtype=int32)),\n",
       " 'io_chrc_period': ('i', False, 0),\n",
       " 'io_chrc_pads_in': ('ints', False, []),\n",
       " 'io_chrc_pads_out': ('ints', False, []),\n",
       " 'code_gen_dir_cppsim': ('s', False, ''),\n",
       " 'executable_path': ('s', False, ''),\n",
       " 'res_hls': ('s', False, '')}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:39:34.910195Z",
     "start_time": "2024-10-08T22:39:34.886901Z"
    }
   },
   "source": [
    "fc_layers = model.get_nodes_by_op_type(\"MVAU_hls\")\n",
    "# (PE, SIMD, in_fifo_depth, out_fifo_depth, ramstyle) for each layer\n",
    "config = [\n",
    "    (16, 49, [16], [64], \"block\"),\n",
    "    (8, 8, [64], [64], \"auto\"),\n",
    "    (8, 8, [64], [64], \"auto\"),\n",
    "    (10, 8, [64], [10], \"distributed\"),\n",
    "]\n",
    "for fcl, (pe, simd, ififo, ofifo, ramstyle) in zip(fc_layers, config):\n",
    "    fcl_inst = getCustomOp(fcl)\n",
    "    fcl_inst.set_nodeattr(\"PE\", pe)\n",
    "    fcl_inst.set_nodeattr(\"SIMD\", simd)\n",
    "    fcl_inst.set_nodeattr(\"inFIFODepths\", ififo)\n",
    "    fcl_inst.set_nodeattr(\"outFIFODepths\", ofifo)\n",
    "    fcl_inst.set_nodeattr(\"ram_style\", ramstyle)\n",
    "    \n",
    "# set parallelism for input quantizer to be same as first layer's SIMD\n",
    "inp_qnt_node = model.get_nodes_by_op_type(\"Thresholding_hls\")[0]\n",
    "inp_qnt = getCustomOp(inp_qnt_node)\n",
    "inp_qnt.set_nodeattr(\"PE\", 49)"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T23:39:25.752898Z",
     "start_time": "2024-10-08T23:39:25.668649Z"
    }
   },
   "source": [
    "model.save(build_dir+\"/tfc_w1_a1_set_folding_factors.onnx\")\n",
    "showInNetron(build_dir+\"/tfc_w1_a1_set_folding_factors.onnx\")"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "save",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m(build_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tfc_w1_a1_set_folding_factors.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      2\u001B[0m showInNetron(build_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tfc_w1_a1_set_folding_factors.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: save"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:42:44.932982Z",
     "start_time": "2024-10-08T22:41:08.909282Z"
    }
   },
   "source": [
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "model = ModelWrapper(build_dir+\"/tfc_w1_a1_set_folding_factors.onnx\")\n",
    "model = model.transform(ZynqBuild(platform = pynq_board, period_ns = target_clk_ns))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fastqnn/finn/src/finn/transformation/fpgadataflow/floorplan.py:107: UserWarning: 10 nodes have no entry in the provided floorplan, SLR was set to -1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[49], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfinn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransformation\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfpgadataflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmake_zynq_proj\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ZynqBuild\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m ModelWrapper(build_dir\u001B[38;5;241m+\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/tfc_w1_a1_set_folding_factors.onnx\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mZynqBuild\u001B[49m\u001B[43m(\u001B[49m\u001B[43mplatform\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mpynq_board\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mperiod_ns\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtarget_clk_ns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/core/modelwrapper.py:140\u001B[0m, in \u001B[0;36mModelWrapper.transform\u001B[0;34m(self, transformation, make_deepcopy, cleanup)\u001B[0m\n\u001B[1;32m    138\u001B[0m model_was_changed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m model_was_changed:\n\u001B[0;32m--> 140\u001B[0m     (transformed_model, model_was_changed) \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[1;32m    142\u001B[0m     transformed_model\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m/home/fastqnn/finn/src/finn/transformation/fpgadataflow/make_zynq_proj.py:345\u001B[0m, in \u001B[0;36mZynqBuild.apply\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    343\u001B[0m kernel_model\u001B[38;5;241m.\u001B[39msave(dataflow_model_filename)\n\u001B[1;32m    344\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m kernel_model\u001B[38;5;241m.\u001B[39mtransform(PrepareIP(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpga_part, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiod_ns))\n\u001B[0;32m--> 345\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m \u001B[43mkernel_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mHLSSynthIP\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    346\u001B[0m kernel_model \u001B[38;5;241m=\u001B[39m kernel_model\u001B[38;5;241m.\u001B[39mtransform(\n\u001B[1;32m    347\u001B[0m     CreateStitchedIP(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfpga_part, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mperiod_ns, sdp_node\u001B[38;5;241m.\u001B[39monnx_node\u001B[38;5;241m.\u001B[39mname, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    348\u001B[0m )\n\u001B[1;32m    349\u001B[0m kernel_model\u001B[38;5;241m.\u001B[39mset_metadata_prop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplatform\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mzynq-iodma\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/core/modelwrapper.py:140\u001B[0m, in \u001B[0;36mModelWrapper.transform\u001B[0;34m(self, transformation, make_deepcopy, cleanup)\u001B[0m\n\u001B[1;32m    138\u001B[0m model_was_changed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m model_was_changed:\n\u001B[0;32m--> 140\u001B[0m     (transformed_model, model_was_changed) \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[1;32m    142\u001B[0m     transformed_model\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/transformation/base.py:112\u001B[0m, in \u001B[0;36mNodeLocalTransformation.apply\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m mp\u001B[38;5;241m.\u001B[39mPool(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_workers) \u001B[38;5;28;01mas\u001B[39;00m p:\n\u001B[0;32m--> 112\u001B[0m         new_nodes_and_bool \u001B[38;5;241m=\u001B[39m \u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplyNodeLocal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mold_nodes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;66;03m# execute without mp.Pool in case of 1 worker to simplify debugging\u001B[39;00m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    115\u001B[0m     new_nodes_and_bool \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapplyNodeLocal(node) \u001B[38;5;28;01mfor\u001B[39;00m node \u001B[38;5;129;01min\u001B[39;00m old_nodes]\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001B[0m, in \u001B[0;36mPool.map\u001B[0;34m(self, func, iterable, chunksize)\u001B[0m\n\u001B[1;32m    362\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmap\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, iterable, chunksize\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    363\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;124;03m    in a list that is returned.\u001B[39;00m\n\u001B[1;32m    366\u001B[0m \u001B[38;5;124;03m    '''\u001B[39;00m\n\u001B[0;32m--> 367\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapstar\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mchunksize\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001B[0m, in \u001B[0;36mApplyResult.get\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    767\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 768\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    769\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mready():\n\u001B[1;32m    770\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTimeoutError\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001B[0m, in \u001B[0;36mApplyResult.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    764\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwait\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 765\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_event\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:607\u001B[0m, in \u001B[0;36mEvent.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    605\u001B[0m signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flag\n\u001B[1;32m    606\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m signaled:\n\u001B[0;32m--> 607\u001B[0m     signaled \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cond\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    608\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m signaled\n",
      "File \u001B[0;32m/usr/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:40:47.416151Z",
     "start_time": "2024-10-08T22:40:46.885199Z"
    }
   },
   "source": [
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "model = model.transform(MakePYNQDriver(\"zynq-iodma\"))"
   ],
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "\n                Ensure CreateDataflowPartition called before driver creation.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mfinn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtransformation\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfpgadataflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmake_pynq_driver\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MakePYNQDriver\n\u001B[0;32m----> 2\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mMakePYNQDriver\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mzynq-iodma\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/lib/python3.10/site-packages/qonnx/core/modelwrapper.py:140\u001B[0m, in \u001B[0;36mModelWrapper.transform\u001B[0;34m(self, transformation, make_deepcopy, cleanup)\u001B[0m\n\u001B[1;32m    138\u001B[0m model_was_changed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    139\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m model_was_changed:\n\u001B[0;32m--> 140\u001B[0m     (transformed_model, model_was_changed) \u001B[38;5;241m=\u001B[39m \u001B[43mtransformation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransformed_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cleanup:\n\u001B[1;32m    142\u001B[0m     transformed_model\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[0;32m/home/fastqnn/finn/src/finn/transformation/fpgadataflow/make_pynq_driver.py:144\u001B[0m, in \u001B[0;36mMakePYNQDriver.apply\u001B[0;34m(self, model)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;66;03m# go down into dataflow partition to get folded shape info etc\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;66;03m# TODO consider setting these as attributes during dataflow partitioning\u001B[39;00m\n\u001B[1;32m    142\u001B[0m i_consumer \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfind_consumer(i_tensor_name)\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[0;32m--> 144\u001B[0m     i_consumer\u001B[38;5;241m.\u001B[39mop_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mStreamingDataflowPartition\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    145\u001B[0m ), \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;124m    Ensure CreateDataflowPartition called before driver creation.\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    147\u001B[0m first_df_model \u001B[38;5;241m=\u001B[39m ModelWrapper(getCustomOp(i_consumer)\u001B[38;5;241m.\u001B[39mget_nodeattr(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m (\n\u001B[1;32m    149\u001B[0m     first_df_model\u001B[38;5;241m.\u001B[39mgraph\u001B[38;5;241m.\u001B[39mnode[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mop_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIODMA_hls\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    150\u001B[0m ), \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFirst partition must hold input IODMA\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "\u001B[0;31mAssertionError\u001B[0m: \n                Ensure CreateDataflowPartition called before driver creation."
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "showInNetron(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")\n",
    "sdp_node_middle = getCustomOp(model.graph.node[1])\n",
    "postsynth_layers = sdp_node_middle.get_nodeattr(\"model\")\n",
    "\n",
    "showInNetron(postsynth_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(postsynth_layers)\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")\n",
    "model.model.metadata_props"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-08T22:30:48.708972Z",
     "start_time": "2024-10-08T22:30:48.394372Z"
    }
   },
   "source": "! ls {model.get_metadata_prop(\"vivado_pynq_proj\")}",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "advanced  basics  end2end_example  Fast-QNN  LFCW1A1.onnx\r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copy\n",
    "from distutils.dir_util import copy_tree\n",
    "\n",
    "# create directory for deployment files\n",
    "deployment_dir = make_build_dir(prefix=\"pynq_deployment_\")\n",
    "model.set_metadata_prop(\"pynq_deployment_dir\", deployment_dir)\n",
    "\n",
    "# get and copy necessary files\n",
    "# .bit and .hwh file\n",
    "bitfile = model.get_metadata_prop(\"bitfile\")\n",
    "hwh_file = model.get_metadata_prop(\"hw_handoff\")\n",
    "deploy_files = [bitfile, hwh_file]\n",
    "\n",
    "for dfile in deploy_files:\n",
    "    if dfile is not None:\n",
    "        copy(dfile, deployment_dir)\n",
    "\n",
    "# driver.py and python libraries\n",
    "pynq_driver_dir = model.get_metadata_prop(\"pynq_driver_dir\")\n",
    "copy_tree(pynq_driver_dir, deployment_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pkgutil import get_data\n",
    "import onnx.numpy_helper as nph\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "raw_i = get_data(\"qonnx.data\", \"onnx/mnist-conv/test_data_set_0/input_0.pb\")\n",
    "x = nph.to_array(onnx.load_tensor_from_string(raw_i))\n",
    "plt.imshow(x.reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = ModelWrapper(build_dir + \"/tfc_w1_a1_post_synthesis.onnx\")\n",
    "iname = model.graph.input[0].name\n",
    "oname = parent_model.graph.output[0].name\n",
    "ishape = model.get_tensor_shape(iname)\n",
    "print(\"Expected network input shape is \" + str(ishape))\n",
    "np.save(deployment_dir + \"/input.npy\", x.reshape(ishape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {deployment_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import make_archive\n",
    "make_archive('deploy-on-pynq-tfc', 'zip', deployment_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```shell\n",
    "unzip deploy-on-pynq-tfc.zip -d finn-tfc-demo\n",
    "cd finn-tfc-demo\n",
    "sudo python3 -m pip install bitstring\n",
    "sudo python3 driver.py --exec_mode=execute --batchsize=1 --bitfile=resizer.bit --inputfile=input.npy\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
